[Назад](brokers.md)

# Apache Kafka
+ [Что такое topic в Apache Kafka](#Что-такое-topic-в-Apache-Kafka)
+ [Что такое partitions в Apache Kafka](#Что-такое-partitions-в-Apache-Kafka)
+ [Как распределяются partitions в кластере Apache Kafka](#Как-распределяются-partitions-в-кластере-Apache-Kafka)
+ [Что такое consumer в Apache Kafka](#Что-такое-consumer-в-Apache-Kafka)
+ [Что такое producer в Apache Kafka](#Что-такое-producer-в-Apache-Kafka)
+ [Что такое broker в Apache Kafka](#Что-такое-broker-в-Apache-Kafka)
+ [Что такое consumer group в Apache Kafka](#Что-такое-consumer-group-в-Apache-Kafka)
+ [Расскажите о API, предоставляемых Apache Kafka.](#Расскажите-о-API-предоставляемых-Apache-Kafka)
+ [Что означает ZooKeeper в Apache Kafka](#Что-означает-ZooKeeper-в-Apache-Kafka)
+ [Можно ли использовать Kafka без ZooKeeper?](#Можно-ли-использовать-Kafka-без-ZooKeeper)
+ [Как поддерживается балансировка нагрузки в Kafka](#Как-поддерживается-балансировка-нагрузки-в-Kafka)
+ [Каковы некоторые различия между Apache Kafka и Flume](#Каковы-некоторые-различия-между-Apache-Kafka-и-Flume)
+ [Каков максимальный размер сообщения, которое может получить Apache Kafka?](#Каков-максимальный-размер-сообщения-которое-может-получить-Apache-Kafka)
+ [Объясните период хранения в кластере Apache Kafka.](#Объясните-период-хранения-в-кластере-Apache-Kafka)
+ [Как долго сообщения сохраняются в Apache Kafka](#Как-долго-сообщения-сохраняются-в-Apache-Kafka)
+ [Какова роль Partitioning Key](#Какова-роль-Partitioning-Key)
+ [Когда в API-интерфейсе Producer возникает QueueFullException](#Когда-в-API-интерфейсе-Producer-возникает-QueueFullException)
+ [Объясните роли leader и follower в Apache Kafka.](#Объясните-роли-leader-и-follower-в-Apache-Kafka)
+ [Какова роль реплик в Apache Kafka](#Какова-роль-реплик-в-Apache-Kafka)
+ [Какова цель ISR в Apache Kafka?](#Какова-цель-ISR-в-Apache-Kafka)
+ [Что подразумевается под partition offset в Apache Kafka?](#Что-подразумевается-под-partition-offset-в-Apache-Kafka)
+ [Объясните отказоустойчивость в Apache Kafka](#Объясните-отказоустойчивость-в-Apache-Kafka)
+ [В чем важность репликации в Kafka?](#В-чем-важность-репликации-в-Kafka)
+ [Как лучше всего запустить сервер Kafka](#Как-лучше-всего-запустить-сервер-Kafka)
+ [Что такое георепликация в Kafka?](#Что-такое-георепликация-в-Kafka)
+ [Что подразумевается под мультитенантностью в Apache Kafka?](#Что-подразумевается-под-мультитенантностью-в-Apache-Kafka)
+ [Объясните фактор репликации темы?](#Объясните-фактор-репликации-темы)
+ [Различие между partitions и replicas в кластере Kafka?](#Различие-между-partitions-и-replicas-в-кластере-Kafka)
+ [Упомяните некоторые недостатки Apache Kafka](#Упомяните-некоторые-недостатки-Apache-Kafka)
+ [Упомяните некоторые реальные примеры использования Apache Kafka?](#Упомяните-некоторые-реальные-примеры-использования-Apache-Kafka)
+ [Почему Apache Kafka предпочтительнее традиционных методов обмена сообщениями?](#Почему-Apache-Kafka-предпочтительнее-традиционных-методов-обмена-сообщениями)
+ [Упомяните некоторые системные инструменты, доступные в Apache Kafka](#Упомяните-некоторые-системные-инструменты-доступные-в-Apache-Kafka)
+ [Упомяните некоторые преимущества Apache Kafka](#Упомяните-некоторые-преимущества-Apache-Kafka)
+ [Какой метод использует Apache Kafka для подключения к клиентам и серверам?](#Какой-метод-использует-Apache-Kafka-для-подключения-к-клиентам-и-серверам)
+ [Определите роль Kafka Streams API и Kafka Connector API.](#Определите-роль-Kafka-Streams-API-и-Kafka-Connector-API)
+ [Что подразумевается под инструментом репликации (Replication Tool)](#Что-подразумевается-под-инструментом-репликации-Replication-Tool)
+ [Как можно настроить Kafka для достижения оптимальной производительности?](#Как-можно-настроить-Kafka-для-достижения-оптимальной-производительности)
+ [В чем разница между Redis и Kafka?](#В-чем-разница-между-Redis-и-Kafka)
+ [Можно ли добавить partitions в существующую тему в Apache Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Какое оптимальное количество partitions для темы?](#Чем-отличается-statement-от-preparedstatement)
+ [Как просмотреть сообщение Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как вывести список всех брокеров, доступных в кластере?](#Как-вызвать-хранимую-процедуру)
+ [Что такое Kafka MirrorMaker?](#Как-закрыть-соединение-с-базой-данных)
+ [Какова роль инструмента миграции Kafka?](#Чем-отличается-statement-от-preparedstatement)
+ [Как вы можете перечислить темы, используемые в Apache Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Каковы ограничения на имена для тем Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Что такое Confluent Replicator?](#Как-закрыть-соединение-с-базой-данных)
+ [Как обеспечить балансировку нагрузки в Apache Kafka при сбое одного Kafka?](#Чем-отличается-statement-от-preparedstatement)
+ [Где хранится метаинформация о темах в кластере Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как отправлять большие сообщения в Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Объясните масштабируемость Apache Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Какая команда запускает ZooKeeper?](#Чем-отличается-statement-от-preparedstatement)
+ [Объясните, как можно добавлять и удалять темы](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните, как можно изменить конфигурации тем в Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Упомяните некоторые различия между Kafka и JMS](#Как-закрыть-соединение-с-базой-данных)
+ [Что подразумевается под Kafka Connect?](#Чем-отличается-statement-от-preparedstatement)
+ [Объясните сжатие сообщений в Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Для чего необходимо сжатие сообщений в Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Каковы некоторые недостатки сжатия сообщений в Apache Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Объясните producer batch в Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Выделите некоторые различия между Kafka Streams и Spark Streaming](#Как-вызвать-хранимую-процедуру)
+ [Объясните, как Apache Kafka обеспечивает безопасность](#Как-закрыть-соединение-с-базой-данных)
+ [Может ли потребитель прочитать более одного раздела из темы?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Можно ли считать Apache Kafka платформой распределенной потоковой передачи?](#Как-вызвать-хранимую-процедуру)
+ [Упомяните некоторые случаи использования, когда Apache Kafka не подходит.](#Как-закрыть-соединение-с-базой-данных)
+ [Определить задержку потребителя (consumer lag) в Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Какие гарантии дает Кафка?](#Как-вызвать-хранимую-процедуру)
+ [Что вы знаете об уплотнении журналов в Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Что вы понимаете о квотах в Кафке?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что подразумевается под идентификатором кластера в Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Можно ли интегрировать Apache Kafka с Apache Storm? Если да, объясните как](#Как-закрыть-соединение-с-базой-данных)
+ [Почему брокера Kafka называют «тупым»?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Когда Kafka выдает исключение BufferExhaustedException?](#Как-вызвать-хранимую-процедуру)
+ [Каковы обязанности брокера-контролера в Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Что вызывает исключение OutOfMemoryException?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как можно изменить время хранения Kafka во время выполнения?](#Как-вызвать-хранимую-процедуру)
+ [Объясните корректное завершение работы в Kafka](#Как-вызвать-хранимую-процедуру)
+ [Можно ли уменьшить количество разделов по теме?](#Как-закрыть-соединение-с-базой-данных)
+ [Как можно расширить кластер в Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объяснение сериализации и десериализации клиентов в Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Что подразумевается под реестром схем Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Для чего можно использовать Kafka Monitoring?](#Как-закрыть-соединение-с-базой-данных)
+ [Как Kafka обеспечивает минимальную модификацию данных при передаче данных от производителя к брокеру и потребителю?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Назовите различные типы API-интерфейса производителя Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Какую роль играют потребительский API Kafka и API-производитель Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Как записать данные из Kafka в базу данных?](#Как-закрыть-соединение-с-базой-данных)
+ [Как лучше всего определить количество тем у одного брокера Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Назовите файл конфигурации, который будет использоваться для настройки свойств ZooKeeper в Kafka](#Как-вызвать-хранимую-процедуру)
+ [Что такое ансамбль ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Что такое Znodes?](#Как-закрыть-соединение-с-базой-данных)
+ [Какие бывают типы Znodes?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как мы можем создавать Znodes?](#Как-вызвать-хранимую-процедуру)
+ [Как мы можем удалить Znodes?](#Как-вызвать-хранимую-процедуру)
+ [Что такое ZooKeeper watches?](#Как-закрыть-соединение-с-базой-данных)
+ [Что такое кворум ZooKeeper?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Каковы преимущества распределенного приложения?](#Как-вызвать-хранимую-процедуру)
+ [Каковы некоторые недостатки распределенного приложения?](#Как-закрыть-соединение-с-базой-данных)
+ [Что подразумевается под протоколом атомной трансляции ZooKeeper (ZAB)?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Где еще используется ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Что такое барьеры ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Объясните Cages в ZooKeeper](#Как-закрыть-соединение-с-базой-данных)
+ [Как называется демон ZooKeeper??](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните CLI в ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Разница между RabbitMQ и Apache Kafka.](#Как-закрыть-соединение-с-базой-данных)
+ [Чем Kafka работает лучше, чем RabbitMQ?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Применяет ли Kafka тот же подход, что и RabbitMQ, для обработки сообщений?](#Как-вызвать-хранимую-процедуру)
+ [Предположим, вы отправляете сообщения в тему Kafka, используя kafkaTemplate. Вы сталкиваетесь с требованием, в котором говорится, что в случае сбоя при доставке сообщений в тему Kafka вы должны повторить отправку сообщений в тот же раздел с тем же смещением. Как этого добиться с помощью kafkatemplate](#Как-вызвать-хранимую-процедуру)
+ [Предположим, что ваши брокеры размещены на AWS EC2. Если вы являетесь производителем или потребителем за пределами сети кластера Kafka, вы сможете связаться с брокерами только через их общедоступный DNS, а не через их частный DNS. Теперь предположим, что ваш клиент (производитель или потребитель) находится за пределами сети вашего кластера Kafka, и вы можете связаться с брокерами только через их общедоступный DNS. Брокер будет возвращать частный DNS брокеров, на которых размещены ведущие разделы, а не общедоступный DNS. К сожалению, поскольку ваш клиент отсутствует в сети вашего кластера Kafka, он не сможет разрешить частный DNS, что приведет к ошибке LEADER NOT AVAILABLE. Как вы решите эту сетевую ошибку?](#Как-закрыть-соединение-с-базой-данных)
+ [Предположим, что производитель записывает записи в тему Kafka со скоростью 10 000 сообщений в секунду, но потребитель может читать только 2 500 сообщений в секунду. Каковы различные стратегии расширения вашей группы потребителей?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что такое продюсерское признание Кафки? Какие типы настроек подтверждения предоставляет Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Как заставить Kafka работать в порядке FIFO?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как производитель Kafka может сохранить ровно exactly one?](#Как-вызвать-хранимую-процедуру)
+ [Может ли группа Kafka Consumer иметь более одного потребителя?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что означает, если реплика долгое время находится вне ISR?](#Как-вызвать-хранимую-процедуру)
+ [Опишите, как можно получить ровно одно сообщение от Kafka в процессе создания данных.?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как создать тему Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Каков метод создания API производителя Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как запустить один Kafka Broker?](#Как-вызвать-хранимую-процедуру)
+ [Как определить размер consumer group для корректной обработки партиций? Какие правила следует соблюдать для оптимальной работы](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Какие семантики отправки сообщений существуют в Кафка?](#Как-вызвать-хранимую-процедуру)
  

## Что такое topic в Apache Kafka?

Поток сообщений, принадлежащих к определенной категории, в Kafka называется topic. Kafka хранит данные в темах, 
разделенных на разделы (partitions)

[к оглавлению](#apache-kafka)

## Что такое partitions в Apache Kafka?

Темы в Kafka разделены на разделы (partitions). Один или несколько потребителей могут одновременно читать данные 
из темы Kafka, читая их из каждого раздела. Разделы разделены по порядку. При создании темы необходимо указать 
количество разделов, хотя это количество произвольно и в дальнейшем может быть изменено.

[к оглавлению](#apache-kafka)

## Как распределяются partitions в кластере Apache Kafka?

Разделы темы Kafka распределены по серверам в кластере Kafka. Каждый сервер Kafka обрабатывает данные и запросы со 
своей долей разделов. Разделы могут быть реплицированы на несколько серверов для обеспечения отказоустойчивости. 
В каждом разделе есть один сервер Kafka, который играет роль лидера для этого раздела. Лидер заботится обо всех 
запросах на чтение и запись для этого конкретного раздела. Лидер может иметь ноль или более последователей. 
Отношения лидера и последователя таковы, что последователи пассивно копируют лидера. В случае неудачи лидера 
роль лидера может взять на себя один из последователей. 

[к оглавлению](#apache-kafka)

## Что такое consumer в Apache Kafka?

Потребители читают данные от брокеров. Потребители могут подписаться на одну или несколько тем и получать опубликованные 
сообщения из этих тем, получая данные от брокеров. Потребители извлекают данные в своем собственном темпе

[к оглавлению](#apache-kafka)

## Что такое producer в Apache Kafka?

Производители могут публиковать сообщения по одной или нескольким темам Kafka. Производители отправляют данные брокерам Kafka. 
Всякий раз, когда производитель публикует сообщения брокеру, брокер добавляет опубликованные сообщения в раздел.
Производитель также может отправлять сообщения в раздел по своему выбору.

[к оглавлению](#apache-kafka)

## Что такое broker в Apache Kafka?

Кластер Kafka содержит один или несколько серверов, которые называются брокерами. Брокер работает как контейнер, 
содержащий несколько тем с различными разделами. Брокер в кластере можно идентифицировать только по связанному 
с ним целочисленному идентификатору. Соединение с каким-либо одним брокером в кластере подразумевает соединение 
со всем кластером. Брокеры в Kafka не содержат полных данных, но знают о других брокерах, темах и разделах кластера.

[к оглавлению](#apache-kafka)

## Что такое consumer group в Apache Kafka?

В Kafka группа потребителей — это набор из одного или нескольких потребителей, которые совместно используют данные 
по одной и той же теме или одному и тому же набору тем. Группа потребителей в основном представляет собой имя приложения. 
Потребители в Кафке обычно принадлежат к определенной группе потребителей. Чтобы получать сообщения из группы потребителей, 
необходимо использовать команду «-group».

[к оглавлению](#apache-kafka)

## Расскажите о API, предоставляемых Apache Kafka

Apache Kafka предоставляет четыре основных API:

+ Kafka Producer API: API-интерфейс производителя позволяет приложениям публиковать сообщения в виде потока записей в 
одной или нескольких темах Kafka.
+ Kafka Consumer API: consumer API позволяет приложениям подписываться на одну или несколько тем Kafka. consumer API
также позволяет приложениям обрабатывать потоки сообщений, созданных для этих тем.
+ API Kafka Streams: API потоков Kafka позволяет приложениям обрабатывать данные в парадигме потоковой обработки. 
Приложение может получать данные в виде входных потоков для одной или нескольких тем, обрабатывать эти потоки, 
а затем отправлять выходные потоки в одну или несколько тем.
+ Kafka Connector API: API соединителя помогает подключать приложения к темам Kafka. Он предоставляет функции для 
управления работой производителей и потребителей и управления связями между ними.

[к оглавлению](#apache-kafka)

## Что означает ZooKeeper в Apache Kafka?

ZooKeeper в Kafka отвечает за управление и координацию кластера Kafka. Он обеспечивает координацию между различными 
узлами в кластере. При возникновении каких-либо изменений в топологии кластера Kafka ZooKeeper уведомляет все узлы 
об этих изменениях. Изменения включают в себя удаление или добавление брокеров или тем.

[к оглавлению](#apache-kafka)

## Можно ли использовать Kafka без ZooKeeper?

Невозможно обойти ZooKeeper в Kafka и подключиться напрямую к серверу Apache Kafka. Следовательно, ответ — нет. Если по 
какой-либо причине ZooKeeper не работает, обслуживание клиентских запросов будет невозможно. Так было, но сейчас
использование ZooKeeper необязательно, т.к. Kafka последних версий может хранить данные об оффсетах внутри себя.

[к оглавлению](#apache-kafka)

## Как поддерживается балансировка нагрузки в Kafka

Балансировкой нагрузки в Kafka занимаются producers. Нагрузка сообщений распределяется между различными partitions, 
сохраняя при этом порядок сообщений. По умолчанию producer выбирает следующий partition для приема данных сообщения, 
используя циклический подход (round-robin approach). Если необходимо использовать другой подход, отличный от циклического 
перебора, пользователи также могут указать точные partitions для сообщения.

[к оглавлению](#apache-kafka)

## Каковы некоторые различия между Apache Kafka и Flume

Apache Kafka и Flume — это распределенные системы данных, но между Kafka и Flume есть определенная разница с 
точки зрения функций, масштабируемости и т. д. В таблице ниже перечислены все основные различия между Apache Kafka и Flume.

|                                                                                                 Apache Kafka | Apache Flume                                                                                                                                             |
|-------------------------------------------------------------------------------------------------------------:|----------------------------------------------------------------------------------------------------------------------------------------------------------|
|                       Kafka оптимизирован для приема и обработки потоковых данных в режиме реального времени | Flume в основном используется для сбора и агрегирования больших объемов данных журналов из нескольких источников в централизованное расположение данных. |
|                                                                                         Легко масштабируется | Не так легко масштабировать, как Kafka.                                                                                                                  |
|                                                                 Может поддерживаться в различных приложениях | Специально разработан для Hadoop                                                                                                                         |
| Apache Kafka работает как кластер и поддерживает автоматическое восстановление, если он устойчив к сбою узла | Инструмент для сбора данных журналов с распределенных веб-серверов                                                                                       | |

[к оглавлению](#apache-kafka)

## Каков максимальный размер сообщения, которое может получить Apache Kafka

Максимальный размер сообщения Kafka по умолчанию составляет 1 МБ (мегабайт). Размер можно изменить в настройках брокера. 
Однако Kafka оптимизирован для обработки небольших сообщений размером 1 КБ.

[к оглавлению](#apache-kafka)

## Объясните период хранения в кластере Apache Kafka

Сообщения, отправляемые в кластеры Kafka, добавляются в один из журналов нескольких разделов (partition logs). 
Эти сообщения остаются в журналах нескольких разделов даже после использования, в течение настраиваемого периода 
времени или до тех пор, пока не будет достигнут настраиваемый размер. Этот настраиваемый период времени, в течение 
которого сообщение остается в журнале, называется периодом хранения (retention period). Сообщение будет доступно в 
течение периода времени, указанного в периоде хранения. Kafka позволяет пользователям настраивать период хранения 
сообщений для каждой темы. Срок хранения сообщения по умолчанию составляет семь дней.

[к оглавлению](#apache-kafka)

## Как долго сообщения сохраняются в Apache Kafka

Сообщения, отправленные в Kafka, сохраняются независимо от того, опубликованы они или нет, в течение определенного периода, 
который называется периодом хранения. Срок хранения можно настроить для темы. Срок хранения по умолчанию составляет 7 дней.

[к оглавлению](#apache-kafka)

## Какова роль Partitioning Key

Сообщения отправляются в различные разделы, связанные с темой, по круговому принципу. Если есть требование 
отправить сообщение в определенный раздел, то с сообщением можно связать ключ. Ключ определяет, в какой раздел 
попадет это конкретное сообщение. Все сообщения с одинаковым ключом попадут в один и тот же раздел. 
Если для сообщения не указан ключ, производитель выберет раздел циклическим способом.

[к оглавлению](#apache-kafka)

## Когда в API-интерфейсе Producer возникает QueueFullException

QueueFullException возникает, когда производитель отправляет сообщения брокеру со скоростью, с которой брокер не может 
справиться. Решением здесь является добавление большего количества брокеров для обработки скорости сообщений, 
поступающих от производителя.

[к оглавлению](#apache-kafka)

## Объясните роли leader и follower в Apache Kafka

В каждом разделе сервера Kafka есть один сервер, который играет роль лидера. Лидер выполняет все задачи чтения и 
записи данных для раздела. Раздел может не иметь followers, иметь одного follower или более одного follower. 
Задача follower — копировать лидера. В таком случае, если в leader произошел сбой, то нагрузку leader может взять на 
себя один из follower.

[к оглавлению](#apache-kafka)

## Какова роль реплик в Apache Kafka

Реплики — это резервные копии разделов в Kafka. На самом деле их никогда не читают и не пишут; скорее, они используются 
для предотвращения потери данных в случае сбоя. Разделы темы публикуются на нескольких серверах в кластере Apache. 
Существует один сервер Kafka, который считается лидером для этого раздела. Лидер обрабатывает все операции чтения 
и записи для определенного раздела. В кластере, где реплицируются разделы тем, может не быть ни одного или более 
последователей. В случае сбоя в лидере данные не теряются из-за наличия реплик на других серверах. 
Кроме того, один из последователей возьмет на себя роль нового лидера.

[к оглавлению](#apache-kafka)

## Какова цель ISR в Apache Kafka?

ISR — in-synch replicas относятся ко всем реплицируемым разделам, которые полностью синхронизированы с ведущим. 
Реплика должна полностью догнать лидера за настраиваемый промежуток времени. По умолчанию это время составляет 10 секунд. 
По истечении этого периода времени, если ведомый не догонит лидера, лидер удалит ведомого из своего ISR, и 
запись продолжится в оставшихся репликах в ISR. Если ведомый возвращается, он сначала обрезает свой журнал до 
последней проверенной точки, а затем догоняет все сообщения после последней контрольной точки от лидера. 
Только когда ведомый полностью догонит, лидер добавит его обратно в ISR.

[к оглавлению](#apache-kafka)

## Что подразумевается под partition offset в Apache Kafka

Каждый раз, когда сообщение или запись назначается разделу в Kafka, ему присваивается смещение (offset). Смещение обозначает 
позицию записи в этом разделе. Запись может быть однозначно идентифицирована внутри раздела с помощью значения смещения. 
Смещение раздела имеет значение только внутри этого конкретного раздела. Записи всегда добавляются в концы разделов, 
поэтому более старые записи будут иметь меньшее смещение.

[к оглавлению](#apache-kafka)

## Объясните отказоустойчивость в Apache Kafka

В Kafka данные раздела копируются на другие брокеры, которые называются репликами. Если в данных раздела на одном узле 
есть точка сбоя, то есть и другие узлы, которые обеспечат резервную копию и обеспечат доступность данных. 
Вот как Kafka обеспечивает отказоустойчивость.

[к оглавлению](#apache-kafka)

## В чем важность репликации в Kafka?

В Kafka репликация обеспечивает отказоустойчивость, гарантируя, что опубликованные сообщения не будут потеряны безвозвратно. 
Даже если узел выходит из строя и они теряются на одном узле из-за ошибки программы, машины или даже из-за 
обновления программного обеспечения, на другом узле существует реплика, которую можно восстановить.

[к оглавлению](#apache-kafka)

## Как лучше всего запустить сервер Kafka

Загрузив последнюю версию Apache Kafka, не забудьте ее распаковать.

Чтобы запустить Kafka, помните, что в вашей локальной среде должна быть установлена Java 8+.

Если вы хотите запустить сервер Kafka, необходимо выполнить следующие команды, чтобы все службы можно было 
запустить в правильном порядке:

Запустите службу ZooKeeper:

$bin/zookeeper-server-start.sh config/zookeeper.properties

Откройте другой терминал и выполните следующую команду, чтобы запустить брокерскую службу Kafka:

$ bin/kafka-server-start.sh config/server.properties

[к оглавлению](#apache-kafka)

## Что такое георепликация в Kafka?

Георепликация в Kafka — это процесс, с помощью которого вы можете дублировать сообщения в одном кластере в 
других центрах обработки данных или облачных регионах. Георепликация предполагает копирование всех файлов и 
позволяет при необходимости хранить их по всему миру. В Kafka георепликацию можно реализовать с помощью 
инструмента Kafka MirrorMaker Tool. Георепликация — это способ обеспечить резервное копирование данных.

[к оглавлению](#apache-kafka)

## Что подразумевается под мультитенантностью в Apache Kafka?

Multi-tenancy относится к режиму работы программного обеспечения, при котором существует несколько экземпляров 
одного или нескольких приложений, работающих в общей среде, независимо друг от друга. Говорят, что 
экземпляры логически изолированы, но физически интегрированы. Чтобы система поддерживала мультитенантность, 
уровень логической изоляции должен быть полным, но уровень физической интеграции может варьироваться. 
Можно сказать, что Kafka является мультитенантным, поскольку он позволяет настраивать различные темы, 
для которых данные могут использоваться или создаваться в одном кластере.

[к оглавлению](#apache-kafka)

## Объясните фактор репликации темы

Коэффициент репликации темы (Topic replication factor) относится к количеству копий темы, присутствующих у нескольких 
брокеров. Коэффициент репликации должен быть больше 1 для обеспечения отказоустойчивости. В таких случаях будет 
копия данных у другого брокера, откуда данные можно будет получить при необходимости.

[к оглавлению](#apache-kafka)

## Различие между partitions и replicas в кластере Kafka

В Kafka темы разделены на части, называемые разделами. Разделы позволяют одному или нескольким потребителям параллельно 
считывать данные с серверов. Ответственность за чтение и запись для одного конкретного раздела осуществляется на 
одном сервере, называемом лидером этого раздела. Кластер может иметь ноль или более последователей, в которых будут 
создаваться реплики данных. Реплики — это просто копии данных в определенном разделе. Последователям не нужно читать 
или записывать разделы отдельно; скорее, они просто копируют лидера.

Разделы в Kafka используются для увеличения пропускной способности. Реплики обеспечивают отказоустойчивость.

[к оглавлению](#apache-kafka)

## Упомяните некоторые недостатки Apache Kafka

+ Настройка сообщений в Kafka приводит к проблемам с производительностью Kafka. Kafka хорошо работает в тех 
случаях, когда сообщение не нужно менять.

+ Kafka не поддерживает выбор темы по шаблону. Точное название темы должно совпадать.

+ В случае больших сообщений брокеры и потребители снижают производительность Kafka, сжимая и распаковывая сообщения. 
Это влияет на пропускную способность и производительность Kafka.

+ Kafka не поддерживает определенные парадигмы сообщений, такие как очередь «точка-точка» и клиентский запрос/ответ.

[к оглавлению](#apache-kafka)

## Упомяните некоторые реальные примеры использования Apache Kafka

+ Брокер сообщений: Kafka способен обрабатывать соответствующие метаданные, т. е. большой объем однотипных сообщений 
или данных, благодаря своей высокой пропускной способности. Kafka можно использовать как систему обмена сообщениями для 
публикации и подписки, которая позволяет удобно читать и записывать данные.

+ Мониторинг операционных данных. Kafka можно использовать для мониторинга показателей, связанных с определенными 
технологиями, например журналов безопасности.

+ Отслеживание активности веб-сайта: Kafka можно использовать для обеспечения успешной отправки и получения данных 
веб-сайтами. Kafka может обрабатывать огромное количество данных, генерируемых веб-сайтами для каждой конкретной 
страницы и действий пользователей.

+ Регистрация данных: функция репликации данных Kafka между узлами может использоваться для восстановления данных на 
вышедших из строя узлах. Kafka также предлагает службу реплицированного журнала из нескольких источников и делает 
реплицированные данные доступными для клиентов.

+ Kafka для потоковой обработки: Kafka может обрабатывать потоковые данные, при этом данные считываются из темы, 
обрабатываются и записываются в новую тему. Новая тема, содержащая обработанные данные, будет доступна пользователям и приложениям.

[к оглавлению](#apache-kafka)

## Почему Apache Kafka предпочтительнее традиционных методов обмена сообщениями

+ В отличие от традиционного метода передачи сообщений, Apache Kafka более масштабируем, поскольку позволяет добавлять 
больше разделов.

+ Kafka не замедляется при добавлении новых потребителей, в отличие от традиционного метода передачи сообщений, 
где производительность как очереди, так и темы снижается с ростом числа потребителей.

+ В Kafka сообщения содержат пару ключ-значение. Ключ используется для разделения на разделы и для размещения 
связанных сообщений в одном разделе. Традиционный метод передачи сообщений обычно не имеет такого метода группировки сообщений.

+ Apache Kafka поставляется с методом контрольной суммы, который используется для обнаружения повреждения сообщений на 
различных серверах; традиционный метод передачи сообщений не позволяет проверить, сохраняется ли целостность сообщения.

+ Apache Kafka поддерживает создание реплик сообщений, т. е. сообщения в Kafka не удаляются после использования и 
доступны в течение времени, указанного в времени хранения. Это также позволяет потребителям еще раз получить любое 
сообщение и повторно обработать его. В любой традиционной системе обмена сообщениями брокер либо удалит успешно 
обработанное сообщение, либо попытается повторно доставить необработанное, что может привести к снижению производительности 
из-за застревания сообщений в очереди.

[к оглавлению](#apache-kafka)

## Упомяните некоторые системные инструменты, доступные в Apache Kafka

Три основных системных инструмента, доступных в Apache Kafka:

+ Kafka Migration Tool — этот инструмент используется для переноса данных в кластере Kafka из одной версии в другую.
+ Kafka MirrorMaker — этот инструмент копирует данные из одного кластера Kafka в другой.
+ Consumer Offset Checker — этот инструмент отображает группу потребителей, тему, разделы, смещение, 
размер журнала и владельца для определенных наборов тем и групп потребителей.

[к оглавлению](#apache-kafka)

## Упомяните некоторые преимущества Apache Kafka

+ Высокая пропускная способность (High throughput): Kafka может обрабатывать тысячи сообщений в секунду. 
Благодаря низкой задержке Kafka поддерживает входящие сообщения с большим объемом и скоростью.
+ Низкая задержка (Low latency): Apache Kafka предлагает всего десять миллисекунд. Это связано с тем, что он отделяет 
сообщения от брокера, позволяя потребителю получать их в любое время.
+ Отказоустойчивость (Fault-tolerant): использование реплик позволяет Apache Kafka быть отказоустойчивым в случае 
сбоя внутри кластера.
+ Долговечность (Durability). Благодаря функции репликации Apache Kafka позволяет данным оставаться более постоянными 
в кластере, а не на диске, что делает их более долговечными.
+ Масштабируемость (Scalability): способность Kafka обрабатывать сообщения большого объема и с высокой скоростью 
делает его очень масштабируемым.
+ Возможность обработки данных в реальном времени: Kafka может обрабатывать конвейеры данных в реальном времени.

[к оглавлению](#apache-kafka)

## Какой метод использует Apache Kafka для подключения к клиентам и серверам

Apache Kafka использует базовый высокопроизводительный протокол TCP, не зависящий от языка, для облегчения связи между 
клиентами и серверами. Между этим протоколом и его предшественником существует обратная совместимость.

[к оглавлению](#apache-kafka)

## Определите роль Kafka Streams API и Kafka Connector API

Streams API позволяет приложению работать в качестве потокового процессора, эффективно преобразуя входные потоки в 
выходные потоки. Streams API отвечает за получение входных потоков из одной или нескольких тем и отправку выходных 
потоков в одну или несколько выходных тем.

Connector API Подключает темы Kapfka к приложениям. Connector API позволяет выполнять и создавать повторно используемые 
производители или потребители, которые связывают темы Kafka с уже существующими приложениями или системами данных.

[к оглавлению](#apache-kafka)

## Что подразумевается под инструментом репликации (Replication Tool)

Replication Tool в Kafka используется для высокоуровневого проектирования поддержки реплик Kafka. Некоторые из доступных 
инструментов репликации:

+ Preferred Replica Leader Election Tool: разделы распределяются между несколькими брокерами в кластере, 
каждая копия называется репликой. Предпочтительная реплика обычно относится к лидеру. Брокеры равномерно распределяют 
роль лидера по кластеру для различных разделов. Тем не менее, дисбаланс может возникнуть со временем из-за сбоев, 
плановых остановок и т. д. В таких случаях вы можете использовать инструмент репликации для поддержания 
балансировки нагрузки, переназначая предпочтительные реплики и, следовательно, лидеров.

+ Topics tool: инструмент тем Kafka отвечает за обработку всех операций управления, связанных с темами, включая
  + Перечисление и описание тем
  + Создание тем
  + Изменение темы
  + Добавление разделов в тему
  + Удаление тем

+ Reassign partitions tool: этот инструмент изменяет реплики, назначенные разделу. Это означает добавление или 
удаление подписчиков, связанных с разделом.
+ StateChangeLogMerger tool: этот инструмент используется для сбора данных от брокеров в определенном кластере, 
форматирования их в центральный журнал и помощи в устранении проблем с изменением состояния. Зачастую проблемы могут 
возникнуть с выбором лидера того или иного раздела. Этот инструмент можно использовать для определения причины проблемы.

Change topic configuration tool: используется для добавления новых параметров конфигурации, изменения существующих 
параметров конфигурации и удаления параметров конфигурации.

[к оглавлению](#apache-kafka)

## Как можно настроить Kafka для достижения оптимальной производительности

Настройка оптимальной производительности включает в себя рассмотрение двух ключевых показателей: **показателей задержки 
(latency measures)**, которые обозначают количество времени, затраченное на обработку одного события, и **показателей 
пропускной способности (throughput measures)**, которые относятся к тому, сколько событий может быть обработано за 
определенное время. Большинство систем оптимизированы либо по задержке, либо по пропускной способности, тогда как 
Kafka может сбалансировать и то, и другое. Настройка Kafka для оптимальной производительности включает в себя следующие шаги:

1) Настройка производителей Kafka: данные, которые производители должны отправлять брокерам, хранятся в пакетном режиме. 
Когда партия готова, производитель отправляет ее брокеру. Что касается задержки и пропускной способности, то для настройки 
производителей необходимо учитывать два параметра: размер пакета и время задержки. Размер партии следует выбирать очень 
тщательно. Если производитель отправляет сообщения постоянно, для максимизации пропускной способности предпочтительнее 
использовать больший размер пакета. Однако если размер пакета выбран очень большим, он может никогда не наполниться 
или заполниться долго, что, в свою очередь, повлияет на задержку. Размер пакета необходимо будет определить с учетом 
характера объема сообщений, отправляемых производителем. Время задержки добавляется, чтобы создать задержку для 
ожидания заполнения большего количества записей в пакете, чтобы были отправлены более крупные записи. Более длительное 
время задержки позволит отправить больше сообщений в одном пакете, но это может привести к снижению задержки. 
С другой стороны, более короткое время задержки приведет к тому, что меньшее количество сообщений будет отправляться быстрее, 
что уменьшит задержку, но также уменьшит пропускную способность.

2) Настройка брокера Kafka: каждый раздел в теме связан с лидером, у которого в дальнейшем будет 0 или более последователей. 
Важно, чтобы лидеры были правильно сбалансированы и следили за тем, чтобы некоторые узлы не были перегружены по 
сравнению с другими.

3) Настройка потребителей Kafka: рекомендуется, чтобы количество разделов для темы было равно количеству потребителей, 
чтобы потребители могли идти в ногу с производителями. В одной и той же группе потребителей разделы распределяются между 
потребителями.

[к оглавлению](#apache-kafka)

## В чем разница между Redis и Kafka

Redis — это сокращенная форма удаленных серверов словарей. Это хранилище «ключ-значение», которое можно использовать в 
качестве хранилища для запросов на чтение и запись. Redis — это база данных без SQL.

|                                                                                                                                                  Redis | Apache Kafka                                                                                                                                                                                                                              |
|-------------------------------------------------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Redis поддерживает доставку сообщений методом push. Это означает, что сообщения, опубликованные в Redis, будут автоматически доставляться потребителям | Apache Kafka поддерживает доставку сообщений по запросу (pull-based delivery). Сообщения, опубликованные брокеру Kafka, не доставляются потребителям автоматически; скорее, потребители должны получать сообщения, когда они готовы к ним |
|                                                                                                           Redis не поддерживает параллельную обработку | Благодаря системе партиционирования в Apache Kafka один или несколько потребителей определенной группы потребителей могут одновременно использовать разделы темы                                                                          |
|                                                 Redis не поддерживает реплики сообщений. Как только сообщения доставляются потребителям, они удаляются | Apache Kafka поддерживает создание реплик сообщений в своем журнале                                                                                                                                                                       |
|                                                                                      Redis — это хранилище в памяти, что делает его быстрее, чем Kafka | Apache Kafka использует дисковое пространство для хранения, что делает его медленнее, чем Redis                                                                                                                                           | 
|                                                 Поскольку Redis представляет собой хранилище в памяти, оно не может обрабатывать большие объемы данных | Поскольку Kafka использует дисковое пространство в качестве основного хранилища, он способен обрабатывать большие объемы данных                                                                                                           | |

[к оглавлению](#apache-kafka)



[Назад](brokers.md)
