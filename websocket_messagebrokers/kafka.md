[Назад](brokers.md)

# Apache Kafka
+ [Что такое topic в Apache Kafka](#Что-такое-topic-в-Apache-Kafka)
+ [Что такое partitions в Apache Kafka](#Что-такое-partitions-в-Apache-Kafka)
+ [Как распределяются partitions в кластере Apache Kafka](#Как-распределяются-partitions-в-кластере-Apache-Kafka)
+ [Что такое consumer в Apache Kafka](#Что-такое-consumer-в-Apache-Kafka)
+ [Что такое producer в Apache Kafka](#Что-такое-producer-в-Apache-Kafka)
+ [Что такое broker в Apache Kafka](#Что-такое-broker-в-Apache-Kafka)
+ [Что такое consumer group в Apache Kafka](#Что-такое-consumer-group-в-Apache-Kafka)
+ [Расскажите о API, предоставляемых Apache Kafka.](#Расскажите-о-API-предоставляемых-Apache-Kafka)
+ [Что означает ZooKeeper в Apache Kafka](#Что-означает-ZooKeeper-в-Apache-Kafka)
+ [Можно ли использовать Kafka без ZooKeeper?](#Можно-ли-использовать-Kafka-без-ZooKeeper)
+ [Как поддерживается балансировка нагрузки в Kafka](#Как-поддерживается-балансировка-нагрузки-в-Kafka)
+ [Каковы некоторые различия между Apache Kafka и Flume](#Каковы-некоторые-различия-между-Apache-Kafka-и-Flume)
+ [Каков максимальный размер сообщения, которое может получить Apache Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните период хранения в кластере Apache Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Как долго сообщения сохраняются в Apache Kafka](#Как-закрыть-соединение-с-базой-данных)
+ [Какова роль Partitioning Key](#Чем-отличается-statement-от-preparedstatement)
+ [Когда в API-интерфейсе Producer возникает QueueFullException](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните роли leader и follower в Apache Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Какова роль реплик в Apache Kafka](#Как-закрыть-соединение-с-базой-данных)
+ [Какова цель ISR в Apache Kafka?](#Чем-отличается-statement-от-preparedstatement)
+ [Что подразумевается под partition offset в Apache Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните отказоустойчивость в Apache Kafka](#Как-вызвать-хранимую-процедуру)
+ [В чем важность репликации в Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Как лучше всего запустить сервер Kafka](#Чем-отличается-statement-от-preparedstatement)
+ [Что такое георепликация в Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что подразумевается под мультитенантностью в Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Объясните фактор репликации темы?](#Как-закрыть-соединение-с-базой-данных)
+ [Различие между partitions и replicas в кластере Kafka?](#Чем-отличается-statement-от-preparedstatement)
+ [Упомяните некоторые недостатки Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Упомяните некоторые реальные примеры использования Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Почему Apache Kafka предпочтительнее традиционных методов обмена сообщениями?](#Как-закрыть-соединение-с-базой-данных)
+ [Упомяните некоторые системные инструменты, доступные в Apache Kafka](#Чем-отличается-statement-от-preparedstatement)
+ [Упомяните некоторые преимущества Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Какой метод использует Apache Kafka для подключения к клиентам и серверам?](#Как-вызвать-хранимую-процедуру)
+ [Определите роль Kafka Streams API и Kafka Connector API.](#Как-закрыть-соединение-с-базой-данных)
+ [Что подразумевается под инструментом репликации (Replication Tool)](#Чем-отличается-statement-от-preparedstatement)
+ [Как можно настроить Kafka для достижения оптимальной производительности?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [В чем разница между Redis и Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Можно ли добавить partitions в существующую тему в Apache Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Какое оптимальное количество partitions для темы?](#Чем-отличается-statement-от-preparedstatement)
+ [Как просмотреть сообщение Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как вывести список всех брокеров, доступных в кластере?](#Как-вызвать-хранимую-процедуру)
+ [Что такое Kafka MirrorMaker?](#Как-закрыть-соединение-с-базой-данных)
+ [Какова роль инструмента миграции Kafka?](#Чем-отличается-statement-от-preparedstatement)
+ [Как вы можете перечислить темы, используемые в Apache Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Каковы ограничения на имена для тем Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Что такое Confluent Replicator?](#Как-закрыть-соединение-с-базой-данных)
+ [Как обеспечить балансировку нагрузки в Apache Kafka при сбое одного Kafka?](#Чем-отличается-statement-от-preparedstatement)
+ [Где хранится метаинформация о темах в кластере Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как отправлять большие сообщения в Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Объясните масштабируемость Apache Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Какая команда запускает ZooKeeper?](#Чем-отличается-statement-от-preparedstatement)
+ [Объясните, как можно добавлять и удалять темы](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните, как можно изменить конфигурации тем в Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Упомяните некоторые различия между Kafka и JMS](#Как-закрыть-соединение-с-базой-данных)
+ [Что подразумевается под Kafka Connect?](#Чем-отличается-statement-от-preparedstatement)
+ [Объясните сжатие сообщений в Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Для чего необходимо сжатие сообщений в Apache Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Каковы некоторые недостатки сжатия сообщений в Apache Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Объясните producer batch в Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Выделите некоторые различия между Kafka Streams и Spark Streaming](#Как-вызвать-хранимую-процедуру)
+ [Объясните, как Apache Kafka обеспечивает безопасность](#Как-закрыть-соединение-с-базой-данных)
+ [Может ли потребитель прочитать более одного раздела из темы?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Можно ли считать Apache Kafka платформой распределенной потоковой передачи?](#Как-вызвать-хранимую-процедуру)
+ [Упомяните некоторые случаи использования, когда Apache Kafka не подходит.](#Как-закрыть-соединение-с-базой-данных)
+ [Определить задержку потребителя (consumer lag) в Apache Kafka](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Какие гарантии дает Кафка?](#Как-вызвать-хранимую-процедуру)
+ [Что вы знаете об уплотнении журналов в Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Что вы понимаете о квотах в Кафке?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что подразумевается под идентификатором кластера в Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Можно ли интегрировать Apache Kafka с Apache Storm? Если да, объясните как](#Как-закрыть-соединение-с-базой-данных)
+ [Почему брокера Kafka называют «тупым»?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Когда Kafka выдает исключение BufferExhaustedException?](#Как-вызвать-хранимую-процедуру)
+ [Каковы обязанности брокера-контролера в Kafka?](#Как-закрыть-соединение-с-базой-данных)
+ [Что вызывает исключение OutOfMemoryException?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как можно изменить время хранения Kafka во время выполнения?](#Как-вызвать-хранимую-процедуру)
+ [Объясните корректное завершение работы в Kafka](#Как-вызвать-хранимую-процедуру)
+ [Можно ли уменьшить количество разделов по теме?](#Как-закрыть-соединение-с-базой-данных)
+ [Как можно расширить кластер в Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объяснение сериализации и десериализации клиентов в Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Что подразумевается под реестром схем Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Для чего можно использовать Kafka Monitoring?](#Как-закрыть-соединение-с-базой-данных)
+ [Как Kafka обеспечивает минимальную модификацию данных при передаче данных от производителя к брокеру и потребителю?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Назовите различные типы API-интерфейса производителя Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Какую роль играют потребительский API Kafka и API-производитель Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Как записать данные из Kafka в базу данных?](#Как-закрыть-соединение-с-базой-данных)
+ [Как лучше всего определить количество тем у одного брокера Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Назовите файл конфигурации, который будет использоваться для настройки свойств ZooKeeper в Kafka](#Как-вызвать-хранимую-процедуру)
+ [Что такое ансамбль ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Что такое Znodes?](#Как-закрыть-соединение-с-базой-данных)
+ [Какие бывают типы Znodes?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как мы можем создавать Znodes?](#Как-вызвать-хранимую-процедуру)
+ [Как мы можем удалить Znodes?](#Как-вызвать-хранимую-процедуру)
+ [Что такое ZooKeeper watches?](#Как-закрыть-соединение-с-базой-данных)
+ [Что такое кворум ZooKeeper?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Каковы преимущества распределенного приложения?](#Как-вызвать-хранимую-процедуру)
+ [Каковы некоторые недостатки распределенного приложения?](#Как-закрыть-соединение-с-базой-данных)
+ [Что подразумевается под протоколом атомной трансляции ZooKeeper (ZAB)?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Где еще используется ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Что такое барьеры ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Объясните Cages в ZooKeeper](#Как-закрыть-соединение-с-базой-данных)
+ [Как называется демон ZooKeeper??](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните CLI в ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Разница между RabbitMQ и Apache Kafka.](#Как-закрыть-соединение-с-базой-данных)
+ [Чем Kafka работает лучше, чем RabbitMQ?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Применяет ли Kafka тот же подход, что и RabbitMQ, для обработки сообщений?](#Как-вызвать-хранимую-процедуру)
+ [Предположим, вы отправляете сообщения в тему Kafka, используя kafkaTemplate. Вы сталкиваетесь с требованием, в котором говорится, что в случае сбоя при доставке сообщений в тему Kafka вы должны повторить отправку сообщений в тот же раздел с тем же смещением. Как этого добиться с помощью kafkatemplate](#Как-вызвать-хранимую-процедуру)
+ [Предположим, что ваши брокеры размещены на AWS EC2. Если вы являетесь производителем или потребителем за пределами сети кластера Kafka, вы сможете связаться с брокерами только через их общедоступный DNS, а не через их частный DNS. Теперь предположим, что ваш клиент (производитель или потребитель) находится за пределами сети вашего кластера Kafka, и вы можете связаться с брокерами только через их общедоступный DNS. Брокер будет возвращать частный DNS брокеров, на которых размещены ведущие разделы, а не общедоступный DNS. К сожалению, поскольку ваш клиент отсутствует в сети вашего кластера Kafka, он не сможет разрешить частный DNS, что приведет к ошибке LEADER NOT AVAILABLE. Как вы решите эту сетевую ошибку?](#Как-закрыть-соединение-с-базой-данных)
+ [Предположим, что производитель записывает записи в тему Kafka со скоростью 10 000 сообщений в секунду, но потребитель может читать только 2 500 сообщений в секунду. Каковы различные стратегии расширения вашей группы потребителей?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что такое продюсерское признание Кафки? Какие типы настроек подтверждения предоставляет Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Как заставить Kafka работать в порядке FIFO?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как производитель Kafka может сохранить ровно exactly one?](#Как-вызвать-хранимую-процедуру)
+ [Может ли группа Kafka Consumer иметь более одного потребителя?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что означает, если реплика долгое время находится вне ISR?](#Как-вызвать-хранимую-процедуру)
+ [Опишите, как можно получить ровно одно сообщение от Kafka в процессе создания данных.?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как создать тему Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Каков метод создания API производителя Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как запустить один Kafka Broker?](#Как-вызвать-хранимую-процедуру)
+ [Как определить размер consumer group для корректной обработки партиций? Какие правила следует соблюдать для оптимальной работы](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Какие семантики отправки сообщений существуют в Кафка?](#Как-вызвать-хранимую-процедуру)
  

## Что такое topic в Apache Kafka?

Поток сообщений, принадлежащих к определенной категории, в Kafka называется topic. Kafka хранит данные в темах, 
разделенных на разделы (partitions)

[к оглавлению](#apache-kafka)

## Что такое partitions в Apache Kafka?

Темы в Kafka разделены на разделы (partitions). Один или несколько потребителей могут одновременно читать данные 
из темы Kafka, читая их из каждого раздела. Разделы разделены по порядку. При создании темы необходимо указать 
количество разделов, хотя это количество произвольно и в дальнейшем может быть изменено.

[к оглавлению](#apache-kafka)

## Как распределяются partitions в кластере Apache Kafka?

Разделы темы Kafka распределены по серверам в кластере Kafka. Каждый сервер Kafka обрабатывает данные и запросы со 
своей долей разделов. Разделы могут быть реплицированы на несколько серверов для обеспечения отказоустойчивости. 
В каждом разделе есть один сервер Kafka, который играет роль лидера для этого раздела. Лидер заботится обо всех 
запросах на чтение и запись для этого конкретного раздела. Лидер может иметь ноль или более последователей. 
Отношения лидера и последователя таковы, что последователи пассивно копируют лидера. В случае неудачи лидера 
роль лидера может взять на себя один из последователей. 

[к оглавлению](#apache-kafka)

## Что такое consumer в Apache Kafka?

Потребители читают данные от брокеров. Потребители могут подписаться на одну или несколько тем и получать опубликованные 
сообщения из этих тем, получая данные от брокеров. Потребители извлекают данные в своем собственном темпе

[к оглавлению](#apache-kafka)

## Что такое producer в Apache Kafka?

Производители могут публиковать сообщения по одной или нескольким темам Kafka. Производители отправляют данные брокерам Kafka. 
Всякий раз, когда производитель публикует сообщения брокеру, брокер добавляет опубликованные сообщения в раздел.
Производитель также может отправлять сообщения в раздел по своему выбору.

[к оглавлению](#apache-kafka)

## Что такое broker в Apache Kafka?

Кластер Kafka содержит один или несколько серверов, которые называются брокерами. Брокер работает как контейнер, 
содержащий несколько тем с различными разделами. Брокер в кластере можно идентифицировать только по связанному 
с ним целочисленному идентификатору. Соединение с каким-либо одним брокером в кластере подразумевает соединение 
со всем кластером. Брокеры в Kafka не содержат полных данных, но знают о других брокерах, темах и разделах кластера.

[к оглавлению](#apache-kafka)

## Что такое consumer group в Apache Kafka?

В Kafka группа потребителей — это набор из одного или нескольких потребителей, которые совместно используют данные 
по одной и той же теме или одному и тому же набору тем. Группа потребителей в основном представляет собой имя приложения. 
Потребители в Кафке обычно принадлежат к определенной группе потребителей. Чтобы получать сообщения из группы потребителей, 
необходимо использовать команду «-group».

[к оглавлению](#apache-kafka)

## Расскажите о API, предоставляемых Apache Kafka

Apache Kafka предоставляет четыре основных API:

+ Kafka Producer API: API-интерфейс производителя позволяет приложениям публиковать сообщения в виде потока записей в 
одной или нескольких темах Kafka.
+ Kafka Consumer API: consumer API позволяет приложениям подписываться на одну или несколько тем Kafka. consumer API
также позволяет приложениям обрабатывать потоки сообщений, созданных для этих тем.
+ API Kafka Streams: API потоков Kafka позволяет приложениям обрабатывать данные в парадигме потоковой обработки. 
Приложение может получать данные в виде входных потоков для одной или нескольких тем, обрабатывать эти потоки, 
а затем отправлять выходные потоки в одну или несколько тем.
+ Kafka Connector API: API соединителя помогает подключать приложения к темам Kafka. Он предоставляет функции для 
управления работой производителей и потребителей и управления связями между ними.

[к оглавлению](#apache-kafka)

## Что означает ZooKeeper в Apache Kafka?

ZooKeeper в Kafka отвечает за управление и координацию кластера Kafka. Он обеспечивает координацию между различными 
узлами в кластере. При возникновении каких-либо изменений в топологии кластера Kafka ZooKeeper уведомляет все узлы 
об этих изменениях. Изменения включают в себя удаление или добавление брокеров или тем.

[к оглавлению](#apache-kafka)

## Можно ли использовать Kafka без ZooKeeper?

Невозможно обойти ZooKeeper в Kafka и подключиться напрямую к серверу Apache Kafka. Следовательно, ответ — нет. Если по 
какой-либо причине ZooKeeper не работает, обслуживание клиентских запросов будет невозможно. Так было, но сейчас
использование ZooKeeper необязательно, т.к. Kafka последних версий может хранить данные об оффсетах внутри себя.

[к оглавлению](#apache-kafka)

## Как поддерживается балансировка нагрузки в Kafka

Балансировкой нагрузки в Kafka занимаются producers. Нагрузка сообщений распределяется между различными partitions, 
сохраняя при этом порядок сообщений. По умолчанию producer выбирает следующий partition для приема данных сообщения, 
используя циклический подход (round-robin approach). Если необходимо использовать другой подход, отличный от циклического 
перебора, пользователи также могут указать точные partitions для сообщения.

[к оглавлению](#apache-kafka)

## Каковы некоторые различия между Apache Kafka и Flume

Apache Kafka и Flume — это распределенные системы данных, но между Kafka и Flume есть определенная разница с 
точки зрения функций, масштабируемости и т. д. В таблице ниже перечислены все основные различия между Apache Kafka и Flume.

|                                                                                                 Apache Kafka | Apache Flume                                                                                                                                             |
|-------------------------------------------------------------------------------------------------------------:|----------------------------------------------------------------------------------------------------------------------------------------------------------|
|                       Kafka оптимизирован для приема и обработки потоковых данных в режиме реального времени | Flume в основном используется для сбора и агрегирования больших объемов данных журналов из нескольких источников в централизованное расположение данных. |
|                                                                                         Легко масштабируется | Не так легко масштабировать, как Kafka.                                                                                                                  |
|                                                                 Может поддерживаться в различных приложениях | Специально разработан для Hadoop                                                                                                                         |
| Apache Kafka работает как кластер и поддерживает автоматическое восстановление, если он устойчив к сбою узла | Инструмент для сбора данных журналов с распределенных веб-серверов                                                                                       | |

[к оглавлению](#apache-kafka)



## Перечислите основные типы данных используемые в JDBC. Как они связаны с типами Java?

| JDBC Type | Java Object Type |
|---------------:|---------------------------|
| __CHAR__ | `String` |
| __VARCHAR__ | `String` |
| __LONGVARCHAR__ | `String` |
| __NUMERIC__ | `java.math.BigDecimal` |
| __DECIMAL__ | `java.math.BigDecimal` |
| __BIT__ | `Boolean` |
| __TINYINT__ | `Integer` |
| __SMALLINT__ | `Integer` |
| __INTEGER__ | `Integer` |
| __BIGINT__ | `Long` |
| __REAL__ | `Float` |
| __FLOAT__ | `Double` |
| __DOUBLE__ | `Double` |
| __BINARY__ | `byte[]` |
| __VARBINARY__ | `byte[]` |
| __LONGVARBINARY__ | `byte[]` |
| __DATE__ | `java.sql.Date` |
| __TIME__ | `java.sql.Time` |
| __TIMESTAMP__ | `java.sql.Timestamp` |
| __CLOB__ | `Clob` |
| __BLOB__ | `Blob` |
| __ARRAY__ | `Array` |
| __STRUCT__ | `Struct`|
| __REF__ | `Ref` |
| __DISTINCT__ | сопоставление базового типа |
| __JAVA_OBJECT__ | базовый класс Java |

[к оглавлению](#apache-kafka)

[Назад](brokers.md)
