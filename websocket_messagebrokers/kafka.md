[Назад](brokers.md)

# Apache Kafka
+ [Что такое topic в Apache Kafka](#Что-такое-topic-в-Apache-Kafka)
+ [Что такое partitions в Apache Kafka](#Что-такое-partitions-в-Apache-Kafka)
+ [Как распределяются partitions в кластере Apache Kafka](#Как-распределяются-partitions-в-кластере-Apache-Kafka)
+ [Что такое consumer в Apache Kafka](#Что-такое-consumer-в-Apache-Kafka)
+ [Что такое producer в Apache Kafka](#Что-такое-producer-в-Apache-Kafka)
+ [Что такое broker в Apache Kafka](#Что-такое-broker-в-Apache-Kafka)
+ [Что такое consumer group в Apache Kafka](#Что-такое-consumer-group-в-Apache-Kafka)
+ [Расскажите о API, предоставляемых Apache Kafka.](#Расскажите-о-API-предоставляемых-Apache-Kafka)
+ [Что означает ZooKeeper в Apache Kafka](#Что-означает-ZooKeeper-в-Apache-Kafka)
+ [Можно ли использовать Kafka без ZooKeeper?](#Можно-ли-использовать-Kafka-без-ZooKeeper)
+ [Как поддерживается балансировка нагрузки в Kafka](#Как-поддерживается-балансировка-нагрузки-в-Kafka)
+ [Каковы некоторые различия между Apache Kafka и Flume](#Каковы-некоторые-различия-между-Apache-Kafka-и-Flume)
+ [Каков максимальный размер сообщения, которое может получить Apache Kafka?](#Каков-максимальный-размер-сообщения-которое-может-получить-Apache-Kafka)
+ [Объясните период хранения в кластере Apache Kafka.](#Объясните-период-хранения-в-кластере-Apache-Kafka)
+ [Как долго сообщения сохраняются в Apache Kafka](#Как-долго-сообщения-сохраняются-в-Apache-Kafka)
+ [Какова роль Partitioning Key](#Какова-роль-Partitioning-Key)
+ [Когда в API-интерфейсе Producer возникает QueueFullException](#Когда-в-API-интерфейсе-Producer-возникает-QueueFullException)
+ [Объясните роли leader и follower в Apache Kafka.](#Объясните-роли-leader-и-follower-в-Apache-Kafka)
+ [Какова роль реплик в Apache Kafka](#Какова-роль-реплик-в-Apache-Kafka)
+ [Какова цель ISR в Apache Kafka?](#Какова-цель-ISR-в-Apache-Kafka)
+ [Что подразумевается под partition offset в Apache Kafka?](#Что-подразумевается-под-partition-offset-в-Apache-Kafka)
+ [Объясните отказоустойчивость в Apache Kafka](#Объясните-отказоустойчивость-в-Apache-Kafka)
+ [В чем важность репликации в Kafka?](#В-чем-важность-репликации-в-Kafka)
+ [Как лучше всего запустить сервер Kafka](#Как-лучше-всего-запустить-сервер-Kafka)
+ [Что такое георепликация в Kafka?](#Что-такое-георепликация-в-Kafka)
+ [Что подразумевается под мультитенантностью в Apache Kafka?](#Что-подразумевается-под-мультитенантностью-в-Apache-Kafka)
+ [Объясните фактор репликации темы?](#Объясните-фактор-репликации-темы)
+ [Различие между partitions и replicas в кластере Kafka?](#Различие-между-partitions-и-replicas-в-кластере-Kafka)
+ [Упомяните некоторые недостатки Apache Kafka](#Упомяните-некоторые-недостатки-Apache-Kafka)
+ [Упомяните некоторые реальные примеры использования Apache Kafka?](#Упомяните-некоторые-реальные-примеры-использования-Apache-Kafka)
+ [Почему Apache Kafka предпочтительнее традиционных методов обмена сообщениями?](#Почему-Apache-Kafka-предпочтительнее-традиционных-методов-обмена-сообщениями)
+ [Упомяните некоторые системные инструменты, доступные в Apache Kafka](#Упомяните-некоторые-системные-инструменты-доступные-в-Apache-Kafka)
+ [Упомяните некоторые преимущества Apache Kafka](#Упомяните-некоторые-преимущества-Apache-Kafka)
+ [Какой метод использует Apache Kafka для подключения к клиентам и серверам?](#Какой-метод-использует-Apache-Kafka-для-подключения-к-клиентам-и-серверам)
+ [Определите роль Kafka Streams API и Kafka Connector API.](#Определите-роль-Kafka-Streams-API-и-Kafka-Connector-API)
+ [Что подразумевается под инструментом репликации (Replication Tool)](#Что-подразумевается-под-инструментом-репликации-Replication-Tool)
+ [Как можно настроить Kafka для достижения оптимальной производительности?](#Как-можно-настроить-Kafka-для-достижения-оптимальной-производительности)
+ [В чем разница между Redis и Kafka?](#В-чем-разница-между-Redis-и-Kafka)
+ [Можно ли добавить partitions в существующую тему в Apache Kafka?](#Можно-ли-добавить-partitions-в-существующую-тему-в-Apache-Kafka)
+ [Какое оптимальное количество partitions для темы?](#Какое-оптимальное-количество-partitions-для-темы)
+ [Как просмотреть сообщение Kafka?](#Как-просмотреть-сообщение-Kafka)
+ [Как вывести список всех брокеров, доступных в кластере?](#Как-вывести-список-всех-брокеров-доступных-в-кластере)
+ [Что такое Kafka MirrorMaker?](#Что-такое-Kafka-MirrorMaker)
+ [Какова роль Kafka Migration Tool?](#Какова-роль-Kafka-Migration-Tool)
+ [Как вы можете перечислить темы, используемые в Apache Kafka?](#Как-вы-можете-перечислить-темы-используемые-в-Apache-Kafka)
+ [Каковы ограничения на имена для тем Kafka?](#Каковы-ограничения-на-имена-для-тем-Kafka)
+ [Что такое Confluent Replicator?](#Что-такое-Confluent-Replicator)
+ [Как обеспечить балансировку нагрузки в Apache Kafka при сбое одного Kafka?](#Как-обеспечить-балансировку-нагрузки-в-Apache-Kafka-при-сбое-одного-Kafka)
+ [Где хранится метаинформация о темах в кластере Kafka?](#Где-хранится-метаинформация-о-темах-в-кластере-Kafka)
+ [Как отправлять большие сообщения в Apache Kafka?](#Как-отправлять-большие-сообщения-в-Apache-Kafka)
+ [Объясните масштабируемость Apache Kafka?](#Объясните-масштабируемость-Apache-Kafka)
+ [Какая команда запускает ZooKeeper?](#Какая-команда-запускает-ZooKeeper)
+ [Объясните, как можно добавлять и удалять темы](#Объясните-как-можно-добавлять-и-удалять-темы)
+ [Объясните, как можно изменить конфигурации тем в Apache Kafka?](#Объясните-как-можно-изменить-конфигурации-тем-в-Apache-Kafka)
+ [Упомяните некоторые различия между Kafka и JMS](#Упомяните-некоторые-различия-между-Kafka-и-JMS)
+ [Что подразумевается под Kafka Connect?](#Что-подразумевается-под-Kafka-Connect)
+ [Объясните сжатие сообщений в Apache Kafka](#Объясните-сжатие-сообщений-в-Apache-Kafka)
+ [Для чего необходимо сжатие сообщений в Apache Kafka?](#Для-чего-необходимо-сжатие-сообщений-в-Apache-Kafka)
+ [Каковы некоторые недостатки сжатия сообщений в Apache Kafka?](#Каковы-некоторые-недостатки-сжатия-сообщений-в-Apache-Kafka)
+ [Объясните producer batch в Apache Kafka](#Объясните-producer-batch-в-Apache-Kafka)
+ [Выделите некоторые различия между Kafka Streams и Spark Streaming](#Выделите-некоторые-различия-между-Kafka-Streams-и-Spark-Streaming)
+ [Объясните, как Apache Kafka обеспечивает безопасность](#Объясните-как-Apache-Kafka-обеспечивает-безопасность)
+ [Может ли потребитель прочитать более одного раздела из темы?](#Может-ли-потребитель-прочитать-более-одного-раздела-из-темы)
+ [Можно ли считать Apache Kafka платформой распределенной потоковой передачи?](#Можно-ли-считать-Apache-Kafka-платформой-распределенной-потоковой-передачи)
+ [Упомяните некоторые случаи использования, когда Apache Kafka не подходит.](#Упомяните-некоторые-случаи-использования-когда-Apache-Kafka-не-подходит)
+ [Определить задержку потребителя (consumer lag) в Apache Kafka](#Определить-задержку-потребителя-consumer-lag-в-Apache-Kafka)
+ [Какие гарантии дает Кафка?](#Какие-гарантии-дает-Кафка)
+ [Что вы знаете об уплотнении журналов в Kafka?](#Что-вы-знаете-об-уплотнении-журналов-в-Kafka)
+ [Что вы понимаете о квотах в Кафке?](#Что-вы-понимаете-о-квотах-в-Кафке)
+ [Что подразумевается под идентификатором кластера в Kafka?](#Что-подразумевается-под-идентификатором-кластера-в-Kafka)
+ [Можно ли интегрировать Apache Kafka с Apache Storm? Если да, объясните как](#Можно-ли-интегрировать-Apache-Kafka-с-Apache-Storm-Если-да-объясните-как)
+ [Почему брокера Kafka называют «тупым»?](#Почему-брокера-Kafka-называют-тупым)
+ [Когда Kafka выдает исключение BufferExhaustedException?](#Когда-Kafka-выдает-исключение-BufferExhaustedException)
+ [Каковы обязанности брокера-контролера в Kafka?](#Каковы-обязанности-брокера-контролера-в-Kafka)
+ [Что вызывает исключение OutOfMemoryException?](#Что-вызывает-исключение-OutOfMemoryException)
+ [Как можно изменить время хранения Kafka во время выполнения?](#Как-можно-изменить-время-хранения-Kafka-во-время-выполнения)
+ [Объясните корректное завершение работы в Kafka](#Объясните корректное завершение работы в Kafka)
+ [Можно ли уменьшить количество разделов по теме?](#Как-закрыть-соединение-с-базой-данных)
+ [Как можно расширить кластер в Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объяснение сериализации и десериализации клиентов в Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Что подразумевается под реестром схем Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Для чего можно использовать Kafka Monitoring?](#Как-закрыть-соединение-с-базой-данных)
+ [Как Kafka обеспечивает минимальную модификацию данных при передаче данных от производителя к брокеру и потребителю?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Назовите различные типы API-интерфейса производителя Kafka.](#Как-вызвать-хранимую-процедуру)
+ [Какую роль играют потребительский API Kafka и API-производитель Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Как записать данные из Kafka в базу данных?](#Как-закрыть-соединение-с-базой-данных)
+ [Как лучше всего определить количество тем у одного брокера Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Назовите файл конфигурации, который будет использоваться для настройки свойств ZooKeeper в Kafka](#Как-вызвать-хранимую-процедуру)
+ [Что такое ансамбль ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Что такое Znodes?](#Как-закрыть-соединение-с-базой-данных)
+ [Какие бывают типы Znodes?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как мы можем создавать Znodes?](#Как-вызвать-хранимую-процедуру)
+ [Как мы можем удалить Znodes?](#Как-вызвать-хранимую-процедуру)
+ [Что такое ZooKeeper watches?](#Как-закрыть-соединение-с-базой-данных)
+ [Что такое кворум ZooKeeper?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Каковы преимущества распределенного приложения?](#Как-вызвать-хранимую-процедуру)
+ [Каковы некоторые недостатки распределенного приложения?](#Как-закрыть-соединение-с-базой-данных)
+ [Что подразумевается под протоколом атомной трансляции ZooKeeper (ZAB)?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Где еще используется ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Что такое барьеры ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Объясните Cages в ZooKeeper](#Как-закрыть-соединение-с-базой-данных)
+ [Как называется демон ZooKeeper??](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Объясните CLI в ZooKeeper?](#Как-вызвать-хранимую-процедуру)
+ [Разница между RabbitMQ и Apache Kafka.](#Как-закрыть-соединение-с-базой-данных)
+ [Чем Kafka работает лучше, чем RabbitMQ?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Применяет ли Kafka тот же подход, что и RabbitMQ, для обработки сообщений?](#Как-вызвать-хранимую-процедуру)
+ [Предположим, вы отправляете сообщения в тему Kafka, используя kafkaTemplate. Вы сталкиваетесь с требованием, в котором говорится, что в случае сбоя при доставке сообщений в тему Kafka вы должны повторить отправку сообщений в тот же раздел с тем же смещением. Как этого добиться с помощью kafkatemplate](#Как-вызвать-хранимую-процедуру)
+ [Предположим, что ваши брокеры размещены на AWS EC2. Если вы являетесь производителем или потребителем за пределами сети кластера Kafka, вы сможете связаться с брокерами только через их общедоступный DNS, а не через их частный DNS. Теперь предположим, что ваш клиент (производитель или потребитель) находится за пределами сети вашего кластера Kafka, и вы можете связаться с брокерами только через их общедоступный DNS. Брокер будет возвращать частный DNS брокеров, на которых размещены ведущие разделы, а не общедоступный DNS. К сожалению, поскольку ваш клиент отсутствует в сети вашего кластера Kafka, он не сможет разрешить частный DNS, что приведет к ошибке LEADER NOT AVAILABLE. Как вы решите эту сетевую ошибку?](#Как-закрыть-соединение-с-базой-данных)
+ [Предположим, что производитель записывает записи в тему Kafka со скоростью 10 000 сообщений в секунду, но потребитель может читать только 2 500 сообщений в секунду. Каковы различные стратегии расширения вашей группы потребителей?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что такое продюсерское признание Кафки? Какие типы настроек подтверждения предоставляет Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Как заставить Kafka работать в порядке FIFO?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как производитель Kafka может сохранить ровно exactly one?](#Как-вызвать-хранимую-процедуру)
+ [Может ли группа Kafka Consumer иметь более одного потребителя?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Что означает, если реплика долгое время находится вне ISR?](#Как-вызвать-хранимую-процедуру)
+ [Опишите, как можно получить ровно одно сообщение от Kafka в процессе создания данных.?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как создать тему Kafka?](#Как-вызвать-хранимую-процедуру)
+ [Каков метод создания API производителя Kafka?](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Как запустить один Kafka Broker?](#Как-вызвать-хранимую-процедуру)
+ [Как определить размер consumer group для корректной обработки партиций? Какие правила следует соблюдать для оптимальной работы](#Как-осуществляется-запрос-к-базе-данных-и-обработка-результатов)
+ [Какие семантики отправки сообщений существуют в Кафка?](#Как-вызвать-хранимую-процедуру)
  

## Что такое topic в Apache Kafka?

Поток сообщений, принадлежащих к определенной категории, в Kafka называется topic. Kafka хранит данные в темах, 
разделенных на разделы (partitions)

[к оглавлению](#apache-kafka)

## Что такое partitions в Apache Kafka?

Темы в Kafka разделены на разделы (partitions). Один или несколько потребителей могут одновременно читать данные 
из темы Kafka, читая их из каждого раздела. Разделы разделены по порядку. При создании темы необходимо указать 
количество разделов, хотя это количество произвольно и в дальнейшем может быть изменено.

[к оглавлению](#apache-kafka)

## Как распределяются partitions в кластере Apache Kafka?

Разделы темы Kafka распределены по серверам в кластере Kafka. Каждый сервер Kafka обрабатывает данные и запросы со 
своей долей разделов. Разделы могут быть реплицированы на несколько серверов для обеспечения отказоустойчивости. 
В каждом разделе есть один сервер Kafka, который играет роль лидера для этого раздела. Лидер заботится обо всех 
запросах на чтение и запись для этого конкретного раздела. Лидер может иметь ноль или более последователей. 
Отношения лидера и последователя таковы, что последователи пассивно копируют лидера. В случае неудачи лидера 
роль лидера может взять на себя один из последователей. 

[к оглавлению](#apache-kafka)

## Что такое consumer в Apache Kafka?

Потребители читают данные от брокеров. Потребители могут подписаться на одну или несколько тем и получать опубликованные 
сообщения из этих тем, получая данные от брокеров. Потребители извлекают данные в своем собственном темпе

[к оглавлению](#apache-kafka)

## Что такое producer в Apache Kafka?

Производители могут публиковать сообщения по одной или нескольким темам Kafka. Производители отправляют данные брокерам Kafka. 
Всякий раз, когда производитель публикует сообщения брокеру, брокер добавляет опубликованные сообщения в раздел.
Производитель также может отправлять сообщения в раздел по своему выбору.

[к оглавлению](#apache-kafka)

## Что такое broker в Apache Kafka?

Кластер Kafka содержит один или несколько серверов, которые называются брокерами. Брокер работает как контейнер, 
содержащий несколько тем с различными разделами. Брокер в кластере можно идентифицировать только по связанному 
с ним целочисленному идентификатору. Соединение с каким-либо одним брокером в кластере подразумевает соединение 
со всем кластером. Брокеры в Kafka не содержат полных данных, но знают о других брокерах, темах и разделах кластера.

[к оглавлению](#apache-kafka)

## Что такое consumer group в Apache Kafka?

В Kafka группа потребителей — это набор из одного или нескольких потребителей, которые совместно используют данные 
по одной и той же теме или одному и тому же набору тем. Группа потребителей в основном представляет собой имя приложения. 
Потребители в Кафке обычно принадлежат к определенной группе потребителей. Чтобы получать сообщения из группы потребителей, 
необходимо использовать команду «-group».

[к оглавлению](#apache-kafka)

## Расскажите о API, предоставляемых Apache Kafka

Apache Kafka предоставляет четыре основных API:

+ Kafka Producer API: API-интерфейс производителя позволяет приложениям публиковать сообщения в виде потока записей в 
одной или нескольких темах Kafka.
+ Kafka Consumer API: consumer API позволяет приложениям подписываться на одну или несколько тем Kafka. consumer API
также позволяет приложениям обрабатывать потоки сообщений, созданных для этих тем.
+ API Kafka Streams: API потоков Kafka позволяет приложениям обрабатывать данные в парадигме потоковой обработки. 
Приложение может получать данные в виде входных потоков для одной или нескольких тем, обрабатывать эти потоки, 
а затем отправлять выходные потоки в одну или несколько тем.
+ Kafka Connector API: API соединителя помогает подключать приложения к темам Kafka. Он предоставляет функции для 
управления работой производителей и потребителей и управления связями между ними.

[к оглавлению](#apache-kafka)

## Что означает ZooKeeper в Apache Kafka?

ZooKeeper в Kafka отвечает за управление и координацию кластера Kafka. Он обеспечивает координацию между различными 
узлами в кластере. При возникновении каких-либо изменений в топологии кластера Kafka ZooKeeper уведомляет все узлы 
об этих изменениях. Изменения включают в себя удаление или добавление брокеров или тем.

[к оглавлению](#apache-kafka)

## Можно ли использовать Kafka без ZooKeeper?

Невозможно обойти ZooKeeper в Kafka и подключиться напрямую к серверу Apache Kafka. Следовательно, ответ — нет. Если по 
какой-либо причине ZooKeeper не работает, обслуживание клиентских запросов будет невозможно. Так было, но сейчас
использование ZooKeeper необязательно, т.к. Kafka последних версий может хранить данные об оффсетах внутри себя.

[к оглавлению](#apache-kafka)

## Как поддерживается балансировка нагрузки в Kafka

Балансировкой нагрузки в Kafka занимаются producers. Нагрузка сообщений распределяется между различными partitions, 
сохраняя при этом порядок сообщений. По умолчанию producer выбирает следующий partition для приема данных сообщения, 
используя циклический подход (round-robin approach). Если необходимо использовать другой подход, отличный от циклического 
перебора, пользователи также могут указать точные partitions для сообщения.

[к оглавлению](#apache-kafka)

## Каковы некоторые различия между Apache Kafka и Flume

Apache Kafka и Flume — это распределенные системы данных, но между Kafka и Flume есть определенная разница с 
точки зрения функций, масштабируемости и т. д. В таблице ниже перечислены все основные различия между Apache Kafka и Flume.

|                                                                                                 Apache Kafka | Apache Flume                                                                                                                                             |
|-------------------------------------------------------------------------------------------------------------:|----------------------------------------------------------------------------------------------------------------------------------------------------------|
|                       Kafka оптимизирован для приема и обработки потоковых данных в режиме реального времени | Flume в основном используется для сбора и агрегирования больших объемов данных журналов из нескольких источников в централизованное расположение данных. |
|                                                                                         Легко масштабируется | Не так легко масштабировать, как Kafka.                                                                                                                  |
|                                                                 Может поддерживаться в различных приложениях | Специально разработан для Hadoop                                                                                                                         |
| Apache Kafka работает как кластер и поддерживает автоматическое восстановление, если он устойчив к сбою узла | Инструмент для сбора данных журналов с распределенных веб-серверов                                                                                       | |

[к оглавлению](#apache-kafka)

## Каков максимальный размер сообщения, которое может получить Apache Kafka

Максимальный размер сообщения Kafka по умолчанию составляет 1 МБ (мегабайт). Размер можно изменить в настройках брокера. 
Однако Kafka оптимизирован для обработки небольших сообщений размером 1 КБ.

[к оглавлению](#apache-kafka)

## Объясните период хранения в кластере Apache Kafka

Сообщения, отправляемые в кластеры Kafka, добавляются в один из журналов нескольких разделов (partition logs). 
Эти сообщения остаются в журналах нескольких разделов даже после использования, в течение настраиваемого периода 
времени или до тех пор, пока не будет достигнут настраиваемый размер. Этот настраиваемый период времени, в течение 
которого сообщение остается в журнале, называется периодом хранения (retention period). Сообщение будет доступно в 
течение периода времени, указанного в периоде хранения. Kafka позволяет пользователям настраивать период хранения 
сообщений для каждой темы. Срок хранения сообщения по умолчанию составляет семь дней.

[к оглавлению](#apache-kafka)

## Как долго сообщения сохраняются в Apache Kafka

Сообщения, отправленные в Kafka, сохраняются независимо от того, опубликованы они или нет, в течение определенного периода, 
который называется периодом хранения. Срок хранения можно настроить для темы. Срок хранения по умолчанию составляет 7 дней.

[к оглавлению](#apache-kafka)

## Какова роль Partitioning Key

Сообщения отправляются в различные разделы, связанные с темой, по круговому принципу. Если есть требование 
отправить сообщение в определенный раздел, то с сообщением можно связать ключ. Ключ определяет, в какой раздел 
попадет это конкретное сообщение. Все сообщения с одинаковым ключом попадут в один и тот же раздел. 
Если для сообщения не указан ключ, производитель выберет раздел циклическим способом.

[к оглавлению](#apache-kafka)

## Когда в API-интерфейсе Producer возникает QueueFullException

QueueFullException возникает, когда производитель отправляет сообщения брокеру со скоростью, с которой брокер не может 
справиться. Решением здесь является добавление большего количества брокеров для обработки скорости сообщений, 
поступающих от производителя.

[к оглавлению](#apache-kafka)

## Объясните роли leader и follower в Apache Kafka

В каждом разделе сервера Kafka есть один сервер, который играет роль лидера. Лидер выполняет все задачи чтения и 
записи данных для раздела. Раздел может не иметь followers, иметь одного follower или более одного follower. 
Задача follower — копировать лидера. В таком случае, если в leader произошел сбой, то нагрузку leader может взять на 
себя один из follower.

[к оглавлению](#apache-kafka)

## Какова роль реплик в Apache Kafka

Реплики — это резервные копии разделов в Kafka. На самом деле их никогда не читают и не пишут; скорее, они используются 
для предотвращения потери данных в случае сбоя. Разделы темы публикуются на нескольких серверах в кластере Apache. 
Существует один сервер Kafka, который считается лидером для этого раздела. Лидер обрабатывает все операции чтения 
и записи для определенного раздела. В кластере, где реплицируются разделы тем, может не быть ни одного или более 
последователей. В случае сбоя в лидере данные не теряются из-за наличия реплик на других серверах. 
Кроме того, один из последователей возьмет на себя роль нового лидера.

[к оглавлению](#apache-kafka)

## Какова цель ISR в Apache Kafka?

ISR — in-synch replicas относятся ко всем реплицируемым разделам, которые полностью синхронизированы с ведущим. 
Реплика должна полностью догнать лидера за настраиваемый промежуток времени. По умолчанию это время составляет 10 секунд. 
По истечении этого периода времени, если ведомый не догонит лидера, лидер удалит ведомого из своего ISR, и 
запись продолжится в оставшихся репликах в ISR. Если ведомый возвращается, он сначала обрезает свой журнал до 
последней проверенной точки, а затем догоняет все сообщения после последней контрольной точки от лидера. 
Только когда ведомый полностью догонит, лидер добавит его обратно в ISR.

[к оглавлению](#apache-kafka)

## Что подразумевается под partition offset в Apache Kafka

Каждый раз, когда сообщение или запись назначается разделу в Kafka, ему присваивается смещение (offset). Смещение обозначает 
позицию записи в этом разделе. Запись может быть однозначно идентифицирована внутри раздела с помощью значения смещения. 
Смещение раздела имеет значение только внутри этого конкретного раздела. Записи всегда добавляются в концы разделов, 
поэтому более старые записи будут иметь меньшее смещение.

[к оглавлению](#apache-kafka)

## Объясните отказоустойчивость в Apache Kafka

В Kafka данные раздела копируются на другие брокеры, которые называются репликами. Если в данных раздела на одном узле 
есть точка сбоя, то есть и другие узлы, которые обеспечат резервную копию и обеспечат доступность данных. 
Вот как Kafka обеспечивает отказоустойчивость.

[к оглавлению](#apache-kafka)

## В чем важность репликации в Kafka?

В Kafka репликация обеспечивает отказоустойчивость, гарантируя, что опубликованные сообщения не будут потеряны безвозвратно. 
Даже если узел выходит из строя и они теряются на одном узле из-за ошибки программы, машины или даже из-за 
обновления программного обеспечения, на другом узле существует реплика, которую можно восстановить.

[к оглавлению](#apache-kafka)

## Как лучше всего запустить сервер Kafka

Загрузив последнюю версию Apache Kafka, не забудьте ее распаковать.

Чтобы запустить Kafka, помните, что в вашей локальной среде должна быть установлена Java 8+.

Если вы хотите запустить сервер Kafka, необходимо выполнить следующие команды, чтобы все службы можно было 
запустить в правильном порядке:

Запустите службу ZooKeeper:

$bin/zookeeper-server-start.sh config/zookeeper.properties

Откройте другой терминал и выполните следующую команду, чтобы запустить брокерскую службу Kafka:

$ bin/kafka-server-start.sh config/server.properties

[к оглавлению](#apache-kafka)

## Что такое георепликация в Kafka?

Георепликация в Kafka — это процесс, с помощью которого вы можете дублировать сообщения в одном кластере в 
других центрах обработки данных или облачных регионах. Георепликация предполагает копирование всех файлов и 
позволяет при необходимости хранить их по всему миру. В Kafka георепликацию можно реализовать с помощью 
инструмента Kafka MirrorMaker Tool. Георепликация — это способ обеспечить резервное копирование данных.

[к оглавлению](#apache-kafka)

## Что подразумевается под мультитенантностью в Apache Kafka?

Multi-tenancy относится к режиму работы программного обеспечения, при котором существует несколько экземпляров 
одного или нескольких приложений, работающих в общей среде, независимо друг от друга. Говорят, что 
экземпляры логически изолированы, но физически интегрированы. Чтобы система поддерживала мультитенантность, 
уровень логической изоляции должен быть полным, но уровень физической интеграции может варьироваться. 
Можно сказать, что Kafka является мультитенантным, поскольку он позволяет настраивать различные темы, 
для которых данные могут использоваться или создаваться в одном кластере.

[к оглавлению](#apache-kafka)

## Объясните фактор репликации темы

Коэффициент репликации темы (Topic replication factor) относится к количеству копий темы, присутствующих у нескольких 
брокеров. Коэффициент репликации должен быть больше 1 для обеспечения отказоустойчивости. В таких случаях будет 
копия данных у другого брокера, откуда данные можно будет получить при необходимости.

[к оглавлению](#apache-kafka)

## Различие между partitions и replicas в кластере Kafka

В Kafka темы разделены на части, называемые разделами. Разделы позволяют одному или нескольким потребителям параллельно 
считывать данные с серверов. Ответственность за чтение и запись для одного конкретного раздела осуществляется на 
одном сервере, называемом лидером этого раздела. Кластер может иметь ноль или более последователей, в которых будут 
создаваться реплики данных. Реплики — это просто копии данных в определенном разделе. Последователям не нужно читать 
или записывать разделы отдельно; скорее, они просто копируют лидера.

Разделы в Kafka используются для увеличения пропускной способности. Реплики обеспечивают отказоустойчивость.

[к оглавлению](#apache-kafka)

## Упомяните некоторые недостатки Apache Kafka

+ Настройка сообщений в Kafka приводит к проблемам с производительностью Kafka. Kafka хорошо работает в тех 
случаях, когда сообщение не нужно менять.

+ Kafka не поддерживает выбор темы по шаблону. Точное название темы должно совпадать.

+ В случае больших сообщений брокеры и потребители снижают производительность Kafka, сжимая и распаковывая сообщения. 
Это влияет на пропускную способность и производительность Kafka.

+ Kafka не поддерживает определенные парадигмы сообщений, такие как очередь «точка-точка» и клиентский запрос/ответ.

[к оглавлению](#apache-kafka)

## Упомяните некоторые реальные примеры использования Apache Kafka

+ Брокер сообщений: Kafka способен обрабатывать соответствующие метаданные, т. е. большой объем однотипных сообщений 
или данных, благодаря своей высокой пропускной способности. Kafka можно использовать как систему обмена сообщениями для 
публикации и подписки, которая позволяет удобно читать и записывать данные.

+ Мониторинг операционных данных. Kafka можно использовать для мониторинга показателей, связанных с определенными 
технологиями, например журналов безопасности.

+ Отслеживание активности веб-сайта: Kafka можно использовать для обеспечения успешной отправки и получения данных 
веб-сайтами. Kafka может обрабатывать огромное количество данных, генерируемых веб-сайтами для каждой конкретной 
страницы и действий пользователей.

+ Регистрация данных: функция репликации данных Kafka между узлами может использоваться для восстановления данных на 
вышедших из строя узлах. Kafka также предлагает службу реплицированного журнала из нескольких источников и делает 
реплицированные данные доступными для клиентов.

+ Kafka для потоковой обработки: Kafka может обрабатывать потоковые данные, при этом данные считываются из темы, 
обрабатываются и записываются в новую тему. Новая тема, содержащая обработанные данные, будет доступна пользователям и приложениям.

[к оглавлению](#apache-kafka)

## Почему Apache Kafka предпочтительнее традиционных методов обмена сообщениями

+ В отличие от традиционного метода передачи сообщений, Apache Kafka более масштабируем, поскольку позволяет добавлять 
больше разделов.

+ Kafka не замедляется при добавлении новых потребителей, в отличие от традиционного метода передачи сообщений, 
где производительность как очереди, так и темы снижается с ростом числа потребителей.

+ В Kafka сообщения содержат пару ключ-значение. Ключ используется для разделения на разделы и для размещения 
связанных сообщений в одном разделе. Традиционный метод передачи сообщений обычно не имеет такого метода группировки сообщений.

+ Apache Kafka поставляется с методом контрольной суммы, который используется для обнаружения повреждения сообщений на 
различных серверах; традиционный метод передачи сообщений не позволяет проверить, сохраняется ли целостность сообщения.

+ Apache Kafka поддерживает создание реплик сообщений, т. е. сообщения в Kafka не удаляются после использования и 
доступны в течение времени, указанного в времени хранения. Это также позволяет потребителям еще раз получить любое 
сообщение и повторно обработать его. В любой традиционной системе обмена сообщениями брокер либо удалит успешно 
обработанное сообщение, либо попытается повторно доставить необработанное, что может привести к снижению производительности 
из-за застревания сообщений в очереди.

[к оглавлению](#apache-kafka)

## Упомяните некоторые системные инструменты, доступные в Apache Kafka

Три основных системных инструмента, доступных в Apache Kafka:

+ Kafka Migration Tool — этот инструмент используется для переноса данных в кластере Kafka из одной версии в другую.
+ Kafka MirrorMaker — этот инструмент копирует данные из одного кластера Kafka в другой.
+ Consumer Offset Checker — этот инструмент отображает группу потребителей, тему, разделы, смещение, 
размер журнала и владельца для определенных наборов тем и групп потребителей.

[к оглавлению](#apache-kafka)

## Упомяните некоторые преимущества Apache Kafka

+ Высокая пропускная способность (High throughput): Kafka может обрабатывать тысячи сообщений в секунду. 
Благодаря низкой задержке Kafka поддерживает входящие сообщения с большим объемом и скоростью.
+ Низкая задержка (Low latency): Apache Kafka предлагает всего десять миллисекунд. Это связано с тем, что он отделяет 
сообщения от брокера, позволяя потребителю получать их в любое время.
+ Отказоустойчивость (Fault-tolerant): использование реплик позволяет Apache Kafka быть отказоустойчивым в случае 
сбоя внутри кластера.
+ Долговечность (Durability). Благодаря функции репликации Apache Kafka позволяет данным оставаться более постоянными 
в кластере, а не на диске, что делает их более долговечными.
+ Масштабируемость (Scalability): способность Kafka обрабатывать сообщения большого объема и с высокой скоростью 
делает его очень масштабируемым.
+ Возможность обработки данных в реальном времени: Kafka может обрабатывать конвейеры данных в реальном времени.

[к оглавлению](#apache-kafka)

## Какой метод использует Apache Kafka для подключения к клиентам и серверам

Apache Kafka использует базовый высокопроизводительный протокол TCP, не зависящий от языка, для облегчения связи между 
клиентами и серверами. Между этим протоколом и его предшественником существует обратная совместимость.

[к оглавлению](#apache-kafka)

## Определите роль Kafka Streams API и Kafka Connector API

Streams API позволяет приложению работать в качестве потокового процессора, эффективно преобразуя входные потоки в 
выходные потоки. Streams API отвечает за получение входных потоков из одной или нескольких тем и отправку выходных 
потоков в одну или несколько выходных тем.

Connector API Подключает темы Kapfka к приложениям. Connector API позволяет выполнять и создавать повторно используемые 
производители или потребители, которые связывают темы Kafka с уже существующими приложениями или системами данных.

[к оглавлению](#apache-kafka)

## Что подразумевается под инструментом репликации (Replication Tool)

Replication Tool в Kafka используется для высокоуровневого проектирования поддержки реплик Kafka. Некоторые из доступных 
инструментов репликации:

+ Preferred Replica Leader Election Tool: разделы распределяются между несколькими брокерами в кластере, 
каждая копия называется репликой. Предпочтительная реплика обычно относится к лидеру. Брокеры равномерно распределяют 
роль лидера по кластеру для различных разделов. Тем не менее, дисбаланс может возникнуть со временем из-за сбоев, 
плановых остановок и т. д. В таких случаях вы можете использовать инструмент репликации для поддержания 
балансировки нагрузки, переназначая предпочтительные реплики и, следовательно, лидеров.

+ Topics tool: инструмент тем Kafka отвечает за обработку всех операций управления, связанных с темами, включая
  + Перечисление и описание тем
  + Создание тем
  + Изменение темы
  + Добавление разделов в тему
  + Удаление тем

+ Reassign partitions tool: этот инструмент изменяет реплики, назначенные разделу. Это означает добавление или 
удаление подписчиков, связанных с разделом.
+ StateChangeLogMerger tool: этот инструмент используется для сбора данных от брокеров в определенном кластере, 
форматирования их в центральный журнал и помощи в устранении проблем с изменением состояния. Зачастую проблемы могут 
возникнуть с выбором лидера того или иного раздела. Этот инструмент можно использовать для определения причины проблемы.

Change topic configuration tool: используется для добавления новых параметров конфигурации, изменения существующих 
параметров конфигурации и удаления параметров конфигурации.

[к оглавлению](#apache-kafka)

## Как можно настроить Kafka для достижения оптимальной производительности

Настройка оптимальной производительности включает в себя рассмотрение двух ключевых показателей: **показателей задержки 
(latency measures)**, которые обозначают количество времени, затраченное на обработку одного события, и **показателей 
пропускной способности (throughput measures)**, которые относятся к тому, сколько событий может быть обработано за 
определенное время. Большинство систем оптимизированы либо по задержке, либо по пропускной способности, тогда как 
Kafka может сбалансировать и то, и другое. Настройка Kafka для оптимальной производительности включает в себя следующие шаги:

1) Настройка производителей Kafka: данные, которые производители должны отправлять брокерам, хранятся в пакетном режиме. 
Когда партия готова, производитель отправляет ее брокеру. Что касается задержки и пропускной способности, то для настройки 
производителей необходимо учитывать два параметра: размер пакета и время задержки. Размер партии следует выбирать очень 
тщательно. Если производитель отправляет сообщения постоянно, для максимизации пропускной способности предпочтительнее 
использовать больший размер пакета. Однако если размер пакета выбран очень большим, он может никогда не наполниться 
или заполниться долго, что, в свою очередь, повлияет на задержку. Размер пакета необходимо будет определить с учетом 
характера объема сообщений, отправляемых производителем. Время задержки добавляется, чтобы создать задержку для 
ожидания заполнения большего количества записей в пакете, чтобы были отправлены более крупные записи. Более длительное 
время задержки позволит отправить больше сообщений в одном пакете, но это может привести к снижению задержки. 
С другой стороны, более короткое время задержки приведет к тому, что меньшее количество сообщений будет отправляться быстрее, 
что уменьшит задержку, но также уменьшит пропускную способность.

2) Настройка брокера Kafka: каждый раздел в теме связан с лидером, у которого в дальнейшем будет 0 или более последователей. 
Важно, чтобы лидеры были правильно сбалансированы и следили за тем, чтобы некоторые узлы не были перегружены по 
сравнению с другими.

3) Настройка потребителей Kafka: рекомендуется, чтобы количество разделов для темы было равно количеству потребителей, 
чтобы потребители могли идти в ногу с производителями. В одной и той же группе потребителей разделы распределяются между 
потребителями.

[к оглавлению](#apache-kafka)

## В чем разница между Redis и Kafka

Redis — это сокращенная форма удаленных серверов словарей. Это хранилище «ключ-значение», которое можно использовать в 
качестве хранилища для запросов на чтение и запись. Redis — это база данных без SQL.

|                                                                                                                                                  Redis | Apache Kafka                                                                                                                                                                                                                              |
|-------------------------------------------------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Redis поддерживает доставку сообщений методом push. Это означает, что сообщения, опубликованные в Redis, будут автоматически доставляться потребителям | Apache Kafka поддерживает доставку сообщений по запросу (pull-based delivery). Сообщения, опубликованные брокеру Kafka, не доставляются потребителям автоматически; скорее, потребители должны получать сообщения, когда они готовы к ним |
|                                                                                                           Redis не поддерживает параллельную обработку | Благодаря системе партиционирования в Apache Kafka один или несколько потребителей определенной группы потребителей могут одновременно использовать разделы темы                                                                          |
|                                                 Redis не поддерживает реплики сообщений. Как только сообщения доставляются потребителям, они удаляются | Apache Kafka поддерживает создание реплик сообщений в своем журнале                                                                                                                                                                       |
|                                                                                      Redis — это хранилище в памяти, что делает его быстрее, чем Kafka | Apache Kafka использует дисковое пространство для хранения, что делает его медленнее, чем Redis                                                                                                                                           | 
|                                                 Поскольку Redis представляет собой хранилище в памяти, оно не может обрабатывать большие объемы данных | Поскольку Kafka использует дисковое пространство в качестве основного хранилища, он способен обрабатывать большие объемы данных                                                                                                           | |

[к оглавлению](#apache-kafka)

## Можно ли добавить partitions в существующую тему в Apache Kafka

Apache Kafka предоставляет команду alter для изменения поведения темы и изменения связанных с ней конфигураций. 
Команду alter можно использовать для добавления дополнительных разделов.

Команда для увеличения разделов до четырех выглядит следующим образом:

./bin/kafka-topics.sh --alter --zookeeper localhost:2181 --topic my-topic --partitions 4

[к оглавлению](#apache-kafka)

## Какое оптимальное количество partitions для темы

Оптимальное количество разделов, на которые должна быть разделена тема, должно быть равно количеству потребителей.

[к оглавлению](#apache-kafka)

## Как просмотреть сообщение Kafka

Для просмотра сообщений можно использовать команду Kafka-console-consumer.sh. Для просмотра сообщений из темы можно 
использовать следующую команду:

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

[к оглавлению](#apache-kafka)

## Как вывести список всех брокеров, доступных в кластере

Два способа получить список доступных брокеров в кластере Apache Kafka:

+ Использование Zookeeper-shell.sh

Zookeeper-shell.sh :2181 ls /brokers/ids

Что даст такой результат:

WATCHER:: Состояние WatchedEvent: Тип SyncConnected: Нет, путь: null [0, 1, 2, 3]

Это указывает на то, что есть четыре действующих брокера — 0,1,2 и 3.

+ Использование zkCli.sh

Сначала вам необходимо войти в клиент ZooKeeper.

zkCli.sh -сервер: 2181

Затем используйте команду ниже, чтобы получить список всех доступных брокеров.

ls /brokers/ids

Оба метода, использованные выше, используют ZooKeeper для получения списка доступных брокеров.

[к оглавлению](#apache-kafka)

## Что такое Kafka MirrorMaker

Kafka MirrorMaker — это автономный инструмент, который позволяет копировать данные из одного кластера Apache Kafka в другой. 
Kafka MirrorMaker будет считывать данные из тем в исходном кластере и записывать темы в целевой кластер с тем же 
именем темы. Исходный и целевой кластеры являются независимыми объектами и могут иметь разное количество разделов и 
разные значения смещения.

[к оглавлению](#apache-kafka)

## Какова роль Kafka Migration Tool

Kafka Migration Tool используется для эффективного перехода из одной среды в другую. 
Его можно использовать для перемещения существующих данных Kafka из старой версии Kafka в более новую версию.

[к оглавлению](#apache-kafka)

## Как вы можете перечислить темы, используемые в Apache Kafka

Запустив ZooKeeper, вы можете перечислить все темы, используя

bin/kafka-topics.sh --list --zookeeper localhost:2181

[к оглавлению](#apache-kafka)

## Каковы ограничения на имена для тем Kafka

Согласно Apache Kafka, при названии тем необходимо соблюдать некоторые юридические правила, а именно:

Максимальная длина — 255 символов (символов и букв). Длина была уменьшена с 255 до 249 в Kafka 0.10.

. (точка), _ (подчеркивание), - (дефис). Однако темы с точкой (.) и подчеркиванием (_) могут вызвать некоторую путаницу 
с внутренними структурами данных, поэтому рекомендуется использовать любой из них, но не оба одновременно.

[к оглавлению](#apache-kafka)

## Что такое Confluent Replicator

Confluent Replicator обеспечивает простую и надежную репликацию тем из исходного кластера в целевой кластер. 
Он непрерывно копирует сообщения из источника в пункт назначения и даже присваивает одинаковые имена темам в кластере назначения.

[к оглавлению](#apache-kafka)

## Как обеспечить балансировку нагрузки в Apache Kafka при сбое одного Kafka

В случае сбоя сервера Kafka, если он был лидером какого-либо раздела, один из его последователей возьмет на себя роль 
нового лидера для обеспечения балансировки нагрузки. Чтобы это произошло, коэффициент репликации темы должен быть 
больше единицы, т. е. у лидера должен быть хотя бы один последователь, который возьмет на себя новую роль лидера.

[к оглавлению](#apache-kafka)

## Где хранится метаинформация о темах в кластере Kafka

В настоящее время в Apache Kafka метаинформация о темах хранится в ZooKeeper. Информация о расположении разделов и 
сведения о конфигурации, относящиеся к теме, хранятся в ZooKeeper в отдельном кластере Kafka.

[к оглавлению](#apache-kafka)

## Как отправлять большие сообщения в Apache Kafka

По умолчанию максимальный размер сообщения, которое можно отправить в Apache Kafka, составляет 1 МБ. Чтобы отправлять 
более крупные сообщения с помощью Kafka, необходимо настроить несколько свойств. Вот детали конфигурации, которые 
необходимо обновить.

На стороне потребителя – fetch.message.max.bytes

У брокера завершите создание реплики — Replica.fetch.max.bytes.

У Брокера конец создания сообщения — message.max.bytes

На стороне брокера для каждой темы – max.message.bytes.

[к оглавлению](#apache-kafka)

## Объясните масштабируемость Apache Kafka

С точки зрения программного обеспечения, масштабируемость приложения — это его способность поддерживать свою производительность, 
когда оно подвергается изменениям в приложениях и требованиях к обработке. В Apache Kafka сообщения, соответствующие 
определенной теме, разделены на разделы. Это позволяет масштабировать размер темы за пределы размера, который поместится 
на одном сервере. Разрешение разделения темы на разделы гарантирует, что Kafka может гарантировать балансировку нагрузки 
между несколькими потребительскими процессами. Кроме того, концепция группы потребителей в Kafka также способствует 
повышению ее масштабируемости. В группе потребителей определенный раздел используется только одним потребителем в группе. 
Это способствует параллелизму использования нескольких сообщений по теме.

[к оглавлению](#apache-kafka)

## Какая команда запускает ZooKeeper

+ bin/zookeeper-server-start.sh

[к оглавлению](#apache-kafka)

## Объясните, как можно добавлять и удалять темы

+ Чтобы создать тему:

kafka/bin/kafka-topics.sh --create \

--zookeeper localhost:2181\

--replication-factor [коэффициент репликации] \

--partitions [количество_разделов] \

--topic [уникальное-имя-темы]

+ Чтобы удалить тему:

Перейдите в ${kafka_home}/config/server.properties и добавьте следующую строку:

Delete.topic.enable = true

Запустите сервер Kafka еще раз с новой конфигурацией:

${kafka_home}/bin/kafka-server-start.sh ~/kafka/config/server.properties

+ Удалить тему:

${kafka_home}/bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic имя-темы

[к оглавлению](#apache-kafka)

## Объясните, как можно изменить конфигурации тем в Apache Kafka

Чтобы добавить конфигурацию:

bin/kafka-configs.sh --zookeeper localhost:2181 --topics --topic_name --alter --add-config x=y

Чтобы удалить конфигурацию:

bin/kafka-configs.sh --zookeeper localhost:2181 --topics --topic_name --alter --delete-config x

Где x — конкретный ключ конфигурации, который необходимо изменить.

[к оглавлению](#apache-kafka)

## Упомяните некоторые различия между Kafka и JMS

|                                                                                                                                                                Apache Kafka | JMS (Java Messaging Service)                                                                                                                                                                                                            |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|                                                                  Система доставки основана на pull механизме. Потребители получают сообщения, когда они готовы их прочитать | Система доставки сообщений основана на модели push. Сообщения автоматически доставляются потребителям |
|                                                                Сообщения сохраняются в течение определенного периода времени, даже после того, как потребитель их прочитает | Как только очередь JMS получает подтверждение того, что потребитель получил сообщение, оно удаляется без возможности восстановления                                                                         |
|                                                                         Kafka гарантирует, что разделы доставляются в том порядке, в котором они присутствовали в сообщении | JMS — очередь, работающая по системе FIFO; он не поддерживает никакую другую форму порядка                                                                                                                                                                     |
|                                                                                                                  Kafka больше подходит для обработки большого объема данных | JMS больше подходит для очень сложных систем с многоузловыми кластерами                                                                                                                                  ||

[к оглавлению](#apache-kafka)

## Что подразумевается под Kafka Connect

Kafka Connect — это инструмент, предоставляемый Apache Kafka, позволяющий масштабируемой и надежной потоковой передаче 
данных между Kafka и другими системами. Это упрощает определение соединителей, которые отвечают за перемещение больших 
коллекций данных в Kafka и из него. Kafka Connect может обрабатывать целые базы данных в качестве входных данных. 
Он также может собирать метрики с серверов приложений в темы Kafka, чтобы эти данные были доступны для потоковой обработки Kafka.

[к оглавлению](#apache-kafka)

## Для чего необходимо сжатие сообщений в Apache Kafka

Сжатие сообщений в Kafka не требует каких-либо изменений в конфигурации брокера или потребителя. Это выгодно по следующим причинам:

+ Благодаря уменьшенному размеру сокращается задержка отправки сообщений в Kafka.
+ Уменьшенная пропускная способность позволяет производителям отправлять брокеру больше сетевых сообщений.
+ Когда данные хранятся в Kafka через облачные платформы, это может снизить стоимость в тех случаях, когда облачные сервисы платные.
+ Сжатие сообщений приводит к снижению нагрузки на диск, что приводит к более быстрому выполнению запросов на чтение и запись.

[к оглавлению](#apache-kafka)

## Каковы некоторые недостатки сжатия сообщений в Apache Kafka

+ Производители в конечном итоге используют несколько циклов ЦП для сжатия.
+ Потребители используют несколько циклов ЦП для распаковки.
+ Сжатие и распаковка приводят к увеличению нагрузки на процессор.

[к оглавлению](#apache-kafka)

## Объясните producer batch в Apache Kafka

Продюсеры пишут сообщения Кафке по одному. Kafka ожидает сообщений, отправляемых в Kafka, создает пакет, помещает в него 
сообщения и ждет, пока этот пакет не заполнится. Только после этого партия отправляется в Кафку. Здесь партия называется 
партией производителя. Размер пакета производителя по умолчанию составляет 16 КБ, но его можно изменить. 
Чем больше размер пакета, тем больше сжатие и пропускная способность запросов производителя.

[к оглавлению](#apache-kafka)

## Выделите некоторые различия между Kafka Streams и Spark Streaming

|                                                                                                                                                                                                            Kafka streams | Spark Streaming                                                                                                                                                                                                                          |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|                                                                                                                                                                   Способен обрабатывать только потоки в реальном времени | Может обрабатывать потоки в реальном времени, а также пакетные процессы |
|                                                                                                                                                 Использование разделов и их реплик позволяет Kafka быть отказоустойчивым | Spark позволяет восстанавливать разделы с помощью Cache и RDD (устойчивый распределенный набор данных)                                                                         |
|                                                                                    Kafka не предоставляет никаких интерактивных режимов. Брокер просто получает данные от производителя и ждет, пока клиент их прочитает | Имеет интерактивные режимы                                                                                                                                                                |
|                                                                                                                                                                           Сообщения остаются постоянными в журнале Kafka | Для сохранения данных необходимо использовать dataframe или какую-либо другую структуру данных                                                                                                                                         | |

[к оглавлению](#apache-kafka)

## Объясните, как Apache Kafka обеспечивает безопасность

Безопасность Kafka состоит из трех компонентов:

+ Шифрование. Все процессы передачи сообщений между брокером Kafka и его различными клиентами защищены с помощью шифрования. 
Это гарантирует, что другие клиенты не смогут перехватить данные. Все сообщения передаются между компонентами в зашифрованном формате.
+ Аутентификация: приложения, использующие брокер Kafka, должны пройти аутентификацию, прежде чем их можно будет подключить 
к Kafka. Только авторизованным приложениям будет разрешено получать или публиковать сообщения. Авторизованные приложения 
будут иметь уникальные идентификаторы и пароли для идентификации.
+ Авторизация: это делается после аутентификации. После аутентификации клиента ему разрешается использовать или 
публиковать сообщения. Авторизация гарантирует, что приложениям можно ограничить доступ на запись, чтобы предотвратить 
загрязнение данных.

[к оглавлению](#apache-kafka)

## Может ли потребитель прочитать более одного раздела из темы

Да, если количество разделов больше, чем количество потребителей в группе потребителей, то потребителю придется 
прочитать более одного раздела из темы.

[к оглавлению](#apache-kafka)

## Можно ли считать Apache Kafka платформой распределенной потоковой передачи

Да, Apache Kafka считается платформой распределенной потоковой передачи (distributed streaming platform). 
Стриминговую платформу можно назвать таковой, если она обладает следующими тремя возможностями:

+ Умеет публиковать и подписываться на потоки данных.
+ Предоставляет услуги, аналогичные службам очереди сообщений или масштабируемой корпоративной системы обмена сообщениями.
+ Хранит потоки записей надежным и отказоустойчивым способом.

Поскольку Kafka отвечает всем трем этим требованиям, ее можно считать потоковой платформой.

Более того, поскольку кластер Kafka состоит из нескольких серверов, которые действуют как брокеры, 
его называют распределенным. Темы Kafka разделены на несколько разделов для обеспечения балансировки нагрузки. 
Брокеры обрабатывают эти разделы параллельно и позволяют нескольким производителям и потребителям параллельно публиковать 
и получать сообщения.

Платформы распределенной потоковой передачи обрабатывают большие объемы данных в режиме реального времени, 
отправляя их на несколько серверов для обработки в реальном времени.

[к оглавлению](#apache-kafka)

## Упомяните некоторые случаи использования, когда Apache Kafka не подходит

+ Kafka создан для обработки больших объемов данных. Если требуется обрабатывать лишь небольшое количество 
сообщений в день, более подходящей будет традиционная система обмена сообщениями.
+ У Kafka есть потоковый API, но он не подходит для выполнения операций преобразования данных. 
Следует избегать использования Kafka для заданий ETL (извлечение, преобразование, загрузка).
+ В случаях, когда необходима простая очередь задач, есть лучшие альтернативы, такие как RabbitMQ.
+ Kafka не годится, если требуется длительное хранение. Он поддерживает сохранение данных только в 
течение определенного периода хранения и не дольше.

[к оглавлению](#apache-kafka)

## Определить задержку потребителя (consumer lag) в Apache Kafka

Consumer lag относится к отставанию между производителями и потребителями Кафки. 
Группы потребителей будут отставать, если скорость производства данных намного превысит скорость их потребления.
Consumer lag — это разница между последним смещением и смещением потребителя.

[к оглавлению](#apache-kafka)

## Какие гарантии дает Кафка

+ Потребители могут видеть сообщения в той же последовательности, в которой их опубликовали производители. 
Порядок отправки сообщений сохраняется.
+ Коэффициент репликации определяет количество реплик. Если коэффициент репликации равен n, то в кластере Kafka имеется 
отказоустойчивость для n-1 серверов.
+ Kafka может гарантировать «at least one» семантику доставки для каждого раздела. Это означает, что при нескольких 
попытках доставки раздела Kafka гарантирует, что он будет доставлен потребителю хотя бы один раз.

[к оглавлению](#apache-kafka)

## Что вы знаете об уплотнении журналов в Kafka

Сжатие журнала (Log compaction) — это метод, с помощью которого Kafka гарантирует, что по крайней мере последнее 
известное значение для каждого ключа сообщения в журнале данных сохраняется для одного topic partition. 
Это дает возможность восстановить состояние после сбоя приложения или в случае сбоя системы. Это позволяет 
перезагрузить кэш после перезапуска приложения во время любого оперативного обслуживания. Сжатие журнала гарантирует, 
что любой потребитель, обрабатывающий журнал с самого начала, сможет просмотреть окончательное состояние всех записей 
в исходном порядке их записи.

[к оглавлению](#apache-kafka)

## Что вы понимаете о квотах в Кафке

Начиная с Kafka 0.9, кластер Kafka может применять квоты (quotas) для производителей и получать любые запросы клиентов. 
Квоты — это пороговые значения скорости передачи данных, определенные для каждого идентификатора клиента. 
Идентификатор клиента используется для идентификации приложения, логически выполняющего запрос клиента. 
Один идентификатор клиента может относиться к нескольким экземплярам производителей и потребителей. Квота будет 
распространяться на всех из них как на единое целое. Квоты гарантируют, что одно приложение не монополизирует ресурсы 
брокера и не приведет к перегрузке сети, потребляя очень большие объемы данных.

[к оглавлению](#apache-kafka)

## Что подразумевается под идентификатором кластера в Kafka

Кластерам Kafka присваиваются уникальные и неизменяемые идентификаторы. Идентификатор конкретного кластера 
известен как cluster id. Идентификатор кластера может содержать не более 22 символов и должен соответствовать 
регулярному выражению [a-zA-Z0-9_\-]+. Он генерируется при первом успешном запуске брокера версии 0.10.1 или новее. 
Брокер пытается получить идентификатор кластера от znode во время запуска. Если znode не существует, брокер генерирует 
новый идентификатор кластера и создает znode с этим идентификатором кластера.

[к оглавлению](#apache-kafka)

## Можно ли интегрировать Apache Kafka с Apache Storm? Если да, объясните как

Да, Apache Kafka и Apache Storm естественным образом дополняют друг друга. Apache Storm — это распределенная система 
обработки в реальном времени, позволяющая обрабатывать очень большие объемы данных. Storm постоянно получает данные из 
настроенных источников и передает их по конвейеру данных в настроенные пункты назначения.

В Storm для потоковой обработки данных совместно работают следующие компоненты:

+ Spout: источник потока. Это непрерывный поток данных журнала.
+ Bolt: Bolt потребляет входные потоки, обрабатывает их и, возможно, генерирует новые потоки.

Вот некоторые классы, которые можно использовать для интеграции Apache Storm и Apache Kafka:

+ BrokerHosts:

BrokerHosts — это интерфейс. ZkHosts и StaticHosts — две их реализации. ZkHosts динамически отслеживает брокеров 
Kafka и используется для хранения их данных в ZooKeeper. StaticHosts используется для ручной настройки брокеров Kafka и их данных.

+ SpoutConfig:

Этот класс является расширением класса KafkaConfig, который поддерживает дополнительную информацию ZooKeeper. Его подпись следующая:

public SpoutConfig (BrokerHosts hosts, string topic, string zkRoot, string id)

Где:

- hosts: любая реализация интерфейса BrokerHosts.

- topic: Название темы

- zkRoot: корневой путь ZooKeeper.

- id: spout хранит состояние смещения, которое он использовал в ZooKeeper. «Идентификатор» здесь должен однозначно 
идентифицировать spout.

**KafkaSpout API**

KafkaSpout — это наша реализация spout, которая будет интегрирована со Storm. Он извлекает сообщения из темы Kafka и 
отправляет их в экосистему Storm в виде кортежей. KafkaSpout получает сведения о конфигурации из SpoutConfig.

**IRichBolt**

Создание болта осуществляется с помощью интерфейса IRichBolt. Bolts принимает кортежи в качестве входных данных, 
обрабатывает их и создает новые кортежи в качестве выходных данных.

Интерфейс IRichBolt имеет методы, перечисленные ниже:

- Prepare — это предоставляет болту среду для выполнения. Исполнитель может вызвать этот метод для инициализации носика.

- Execute: используется для обработки одного входного кортежа.

- Cleanup — это вызывается, когда болт готов к закрытию.

- DeclareOutputFields — используется для указания схемы вывода кортежа.

[к оглавлению](#apache-kafka)

## Почему брокера Kafka называют «тупым»

Брокер Kafka не ведет учет того, какие сообщения прочитали потребители. Он просто сохраняет все сообщения в своей очереди 
в течение фиксированного времени, известного как время хранения, после чего сообщения удаляются. Ответственность 
за извлечение сообщений из очереди лежит на потребителе. Следовательно, говорят, что Kafka имеет архитектуру 
«умный клиент и тупой брокер».

[к оглавлению](#apache-kafka)

## Когда Kafka выдает исключение BufferExhaustedException

BufferExhaustedException генерируется, когда производитель не может выделить память для записи из-за переполнения буфера. 
Исключение выдается, если производитель находится в неблокирующем режиме и скорость создания данных превышает скорость, 
с которой данные отправляются из буфера в течение достаточно долгого времени, чтобы выделенный буфер был исчерпан.

[к оглавлению](#apache-kafka)

## Каковы обязанности брокера-контролера в Kafka

Основная роль Контроллера — управление и координация кластера Kafka вместе с Apache ZooKeeper. 
Роль контроллера может взять на себя любой брокер в кластере. Однако после запуска приложения в кластере может 
быть только один брокер-контроллер. Когда брокер запустится, он попытается создать узел контроллера в ZooKeeper. 
Первый брокер, создавший этот узел контроллера, становится контроллером.

Контролер несет ответственность за:

+ создание и удаление тем;
+ Добавление разделов и назначение лидеров разделам
+ Управление брокерами в кластере: добавление новых брокеров, закрытие активного брокера и сбои брокера.
+ Выборы лидера
+ Перераспределение разделов.

[к оглавлению](#apache-kafka)

## Что вызывает исключение OutOfMemoryException

Исключение OutOfMemoryException может возникнуть, если потребители отправляют большие сообщения или если 
наблюдается резкий скачок количества сообщений, при этом потребитель отправляет сообщения со скоростью, превышающей 
скорость последующей обработки. Это приводит к тому, что очередь сообщений переполняется, занимая память.

[к оглавлению](#apache-kafka)

## Как можно изменить время хранения Kafka во время выполнения

Время хранения можно настроить в Kafka для темы. Срок хранения темы по умолчанию составляет семь дней. 
Время хранения можно настроить при настройке новой темы. Log.retention.hours — это свойство брокера, которое 
используется для установки времени хранения при создании темы. Однако, когда необходимо изменить конфигурации для 
текущей темы, необходимо использовать kafka-topic.sh.

Правильная команда зависит от используемой версии Kafka.

До версии 0.8.2 следует использовать команду kafka-topics.sh --alter.

Начиная с версии 0.9.0, используйте kafka-configs.sh --alter

[к оглавлению](#apache-kafka)

## Объясните корректное завершение работы в Kafka

Любое отключение или сбой брокера будет автоматически обнаружен кластером Apache. В таком случае новые лидеры будут 
выбраны для разделов, которые ранее обрабатывались этой машиной. Это может произойти из-за сбоя сервера или даже если
он намеренно отключен для обслуживания или каких-либо изменений конфигурации. В случаях, когда сервер намеренно отключается, 
Kafka поддерживает изящный механизм остановки сервера, а не просто его уничтожение.

Всякий раз, когда сервер остановлен:

Kafka гарантирует, что все его журналы синхронизируются на диск, чтобы избежать необходимости восстановления 
журналов при перезапуске. Поскольку восстановление журнала требует времени, это может ускорить намеренный перезапуск.

Любые разделы, для которых сервер является ведущим, будут перенесены в реплики перед выключением. Это гарантирует, что 
передача лидерства произойдет быстрее, а время, в течение которого каждый раздел будет недоступен, сократится до 
нескольких миллисекунд.

[к оглавлению](#apache-kafka)

[Назад](brokers.md)
